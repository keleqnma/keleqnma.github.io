<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>盗版小说网站爬虫指北</title>
    <link href="/2020/11/14/%E7%9B%97%E7%89%88%E5%B0%8F%E8%AF%B4%E7%88%AC%E8%99%AB%E6%8C%87%E5%8C%97/"/>
    <url>/2020/11/14/%E7%9B%97%E7%89%88%E5%B0%8F%E8%AF%B4%E7%88%AC%E8%99%AB%E6%8C%87%E5%8C%97/</url>
    
    <content type="html"><![CDATA[<p>由于前段日子误操作把手机里的小说都删了，就重操旧业爬取盗版小说网站，小说爬虫算是轻量级爬虫，盗版小说网站比起正版小说网站，没什么验证码，用vue和react的都少，网页三剑客所见即所得，也不用selenium这种东西去模拟点击，当然，盗版小说网站服务器通常很烂很烂，你要是爬猛了发现速度突然慢下来请求大面积失败了，除了ip拦截的可能性之外，也有可能是你爬虫把人家服务器搞崩了……</p><p>总体来说，大部分盗版小说网站可以说对爬虫没什么防范措施，顶多就是你爬猛了给你封ip，非常适合用来练手，爬起来也很有快感！那么要确定的就是两个事情：</p><ol><li>这个网站能承受多少请求？封请求的上限是多少？</li><li>你的爬虫机，你的网络速度上限是多少？</li></ol><p>确定了之后调整一下参数，剩下来的就是通用的技术流程。</p><h2 id="1-如何定位元素？"><a href="#1-如何定位元素？" class="headerlink" title="1. 如何定位元素？"></a>1. 如何定位元素？</h2><h2 id="2-多线程如何稳定爬取速率？"><a href="#2-多线程如何稳定爬取速率？" class="headerlink" title="2. 多线程如何稳定爬取速率？"></a>2. 多线程如何稳定爬取速率？</h2><h2 id="3-DNS解析缓存？"><a href="#3-DNS解析缓存？" class="headerlink" title="3. DNS解析缓存？"></a>3. DNS解析缓存？</h2><h2 id="4-IP池？"><a href="#4-IP池？" class="headerlink" title="4. IP池？"></a>4. IP池？</h2><h2 id="5-长连接短连接？"><a href="#5-长连接短连接？" class="headerlink" title="5. 长连接短连接？"></a>5. 长连接短连接？</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>每天一题 Leetcode 166. Fraction to Recurring Decimal</title>
    <link href="/2020/10/28/%E6%AF%8F%E5%A4%A9%E4%B8%80%E9%A2%98-Leetcode-166-Fraction-to-Recurring-Decimal/"/>
    <url>/2020/10/28/%E6%AF%8F%E5%A4%A9%E4%B8%80%E9%A2%98-Leetcode-166-Fraction-to-Recurring-Decimal/</url>
    
    <content type="html"><![CDATA[<p>利用哈希表找重复情况，注意corner case。</p><a id="more"></a><h1 id="每天一题-Leetcode-166-Fraction-to-Recurring-Decimal"><a href="#每天一题-Leetcode-166-Fraction-to-Recurring-Decimal" class="headerlink" title="每天一题 Leetcode 166. Fraction to Recurring Decimal"></a>每天一题 Leetcode 166. Fraction to Recurring Decimal</h1><h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1. 题目"></a>1. 题目</h2><p><a href="https://leetcode.com/problems/fraction-to-recurring-decimal/">https://leetcode.com/problems/fraction-to-recurring-decimal/</a></p><div class="note note-primary">            <p>Given two integers representing the numerator and denominator of a fraction, return the fraction in string format.</p><p>If the fractional part is repeating, enclose the repeating part in parentheses.</p><p>If multiple answers are possible, return any of them.</p><p>It is guaranteed that the length of the answer string is less than 104 for all the given inputs.</p><pre><code>Example 1:Input: numerator = 1, denominator = 2Output: &quot;0.5&quot;Example 2:Input: numerator = 2, denominator = 1Output: &quot;2&quot;Example 3:Input: numerator = 2, denominator = 3Output: &quot;0.(6)&quot;Example 4:Input: numerator = 4, denominator = 333Output: &quot;0.(012)&quot;Example 5:Input: numerator = 1, denominator = 5Output: &quot;0.2&quot;</code></pre><p>Constraints:</p><ul><li><p>-231 &lt;= numerator, denominator &lt;= 231 - 1</p></li><li><p>denominator != 0 </p></li></ul>          </div><h2 id="2-解法"><a href="#2-解法" class="headerlink" title="2. 解法"></a>2. 解法</h2><p>代码：</p><pre><code class="hljs go"><span class="hljs-keyword">import</span>(    <span class="hljs-string">&quot;strconv&quot;</span>    <span class="hljs-string">&quot;fmt&quot;</span>)<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">abs</span><span class="hljs-params">(n <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">int</span></span> &#123;    <span class="hljs-keyword">if</span> n &gt; <span class="hljs-number">0</span> &#123;        <span class="hljs-keyword">return</span> n    &#125;    <span class="hljs-keyword">return</span> -n&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">fractionToDecimal</span><span class="hljs-params">(numerator <span class="hljs-keyword">int</span>, denominator <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">string</span></span> &#123;    <span class="hljs-keyword">var</span> res <span class="hljs-keyword">string</span>    <span class="hljs-keyword">if</span> ((numerator &gt; <span class="hljs-number">0</span>) &amp;&amp; (denominator &lt; <span class="hljs-number">0</span>)) || ((numerator &lt; <span class="hljs-number">0</span>) &amp;&amp; (denominator &gt; <span class="hljs-number">0</span>))&#123;        res += <span class="hljs-string">&quot;-&quot;</span>    &#125;        num := abs(numerator)    den := abs(denominator)    res += strconv.Itoa(num/den)    num %= den    <span class="hljs-keyword">if</span> num == <span class="hljs-number">0</span>&#123;        <span class="hljs-keyword">return</span> res    &#125;        res += <span class="hljs-string">&quot;.&quot;</span>    numMap := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">int</span>]<span class="hljs-keyword">int</span>)    numMap[num] = <span class="hljs-built_in">len</span>(res)    <span class="hljs-keyword">for</span> num != <span class="hljs-number">0</span> &#123;        num *= <span class="hljs-number">10</span>        res += strconv.Itoa(num/den)        num %= den        <span class="hljs-keyword">if</span> index, ok := numMap[num];ok&#123;            res = res[:index] + <span class="hljs-string">&quot;(&quot;</span> + res[index:] + <span class="hljs-string">&quot;)&quot;</span>            <span class="hljs-keyword">break</span>        &#125;<span class="hljs-keyword">else</span>&#123;            numMap[num] = <span class="hljs-built_in">len</span>(res)        &#125;    &#125;    <span class="hljs-keyword">return</span> res&#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
      <category>LeetCode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>哈希</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>从0实现Golang高性能定时器</title>
    <link href="/2020/10/26/%E4%BB%8E0%E5%AE%9E%E7%8E%B0Golang%E9%AB%98%E6%80%A7%E8%83%BD%E5%AE%9A%E6%97%B6%E5%99%A8/"/>
    <url>/2020/10/26/%E4%BB%8E0%E5%AE%9E%E7%8E%B0Golang%E9%AB%98%E6%80%A7%E8%83%BD%E5%AE%9A%E6%97%B6%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<p>现在在做的业务有大量循环定期任务，目前用的是小根堆+定期check，前几天面试，面试官建议可以用时间轮，但是golang还没有我特别喜欢的实现，所以决定自己写（zao）一（lun）个（zi）。</p><p>希望的feature：</p><ol><li>自定义时间粒度。</li><li>支持一次性定时，周期性定时。</li><li><strong>高性能</strong>。</li><li>支持传函数参数。（个人需求）</li><li>支持sleep。</li></ol><h2 id="预备资料"><a href="#预备资料" class="headerlink" title="预备资料"></a>预备资料</h2><table><thead><tr><th>定时器库</th><th>实现原理</th><th>优化点</th></tr></thead><tbody><tr><td>Go1.13 timer</td><td>64个time bucket，每个都是一个最小四叉堆（即小根堆）。</td><td>分桶，四叉堆对缓存更友好。</td></tr><tr><td>Go1.14 timer</td><td></td><td></td></tr><tr><td>Netty</td><td></td><td></td></tr><tr><td>kafka</td><td></td><td></td></tr></tbody></table><h2 id="总体结构"><a href="#总体结构" class="headerlink" title="总体结构"></a>总体结构</h2><h2 id="逻辑"><a href="#逻辑" class="headerlink" title="逻辑"></a>逻辑</h2><h2 id="benchmark"><a href="#benchmark" class="headerlink" title="benchmark"></a>benchmark</h2>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>2020年的技术向Flag</title>
    <link href="/2020/10/26/2020%E7%9A%84Flag/"/>
    <url>/2020/10/26/2020%E7%9A%84Flag/</url>
    
    <content type="html"><![CDATA[<p>2020还剩两个月，给自己立几个Flag吧。</p><a id="more"></a><ol><li><p>（优先级：高）6.824 的lab3做完并且写完实现笔记。</p></li><li><p>（优先级：高）继续优化CocoCache，优化GC开销。</p></li><li><p>（优先级：中）业务驱动的需求：用Go实现一个时间轮算法，参考实现：<a href="https://github.com/rfyiamcool/go-ringtimer%EF%BC%8C">https://github.com/rfyiamcool/go-ringtimer，</a>  <a href="https://github.com/wuYin/timewheel%E3%80%82">https://github.com/wuYin/timewheel。</a></p></li><li><p>（优先级：低）模仿Gin写一个web框架。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>个人</category>
      
    </categories>
    
    
    <tags>
      
      <tag>黄狗杂谈</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每天一题 Leetcode 填充每个节点的下一个右侧节点指针 II</title>
    <link href="/2020/10/21/%E6%AF%8F%E5%A4%A9%E4%B8%80%E9%A2%98-%E5%A1%AB%E5%85%85%E8%8A%82%E7%82%B9/"/>
    <url>/2020/10/21/%E6%AF%8F%E5%A4%A9%E4%B8%80%E9%A2%98-%E5%A1%AB%E5%85%85%E8%8A%82%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<p>一道特殊的二叉树BFS题目。</p><a id="more"></a><h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1. 题目"></a>1. 题目</h2><div class="note note-primary">            <p>给定一个二叉树</p><pre><code>struct Node {  int val;  Node *left;  Node *right;  Node *next;}</code></pre><p>填充它的每个 next 指针，让这个指针指向其下一个右侧节点。如果找不到下一个右侧节点，则将 next 指针设置为 NULL。</p><p>初始状态下，所有 next 指针都被设置为 NULL。</p><p>进阶：</p><p>你只能使用常量级额外空间。<br>使用递归解题也符合要求，本题中递归程序占用的栈空间不算做额外的空间复杂度。</p>          </div><h2 id="2-解法"><a href="#2-解法" class="headerlink" title="2. 解法"></a>2. 解法</h2><p>现在网上的解法是适用于完全二叉树（原题是完全二叉树）的，但是对于普通二叉树，就不实用了。把握住两个点：</p><ol><li>利用next节点可以在二叉树的同一级内自由跳转。</li><li>需要找到同一级内离你最近的右侧节点。</li></ol><p>很明显可以用BFS来做，将代码修改一下加一个BFS逻辑就可以了（不是典型BFS代码的样式，没有队列，但是思想是BFS，分层遍历）。</p><ol><li>利用next节点从左向右遍历当前节点的层次，帮当前节点的下一层节点找到他们的next节点。</li><li>用一个变量记下下一个节点的最左节点。</li><li>再遍历下一层，循环往复。</li></ol><pre><code class="hljs go"><span class="hljs-comment">/**</span><span class="hljs-comment"> * Definition for a Node.</span><span class="hljs-comment"> * type Node struct &#123;</span><span class="hljs-comment"> *     Val int</span><span class="hljs-comment"> *     Left *Node</span><span class="hljs-comment"> *     Right *Node</span><span class="hljs-comment"> *     Next *Node</span><span class="hljs-comment"> * &#125;</span><span class="hljs-comment"> */</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">connect</span><span class="hljs-params">(root *Node)</span> *<span class="hljs-title">Node</span></span> &#123;    <span class="hljs-keyword">if</span> root == <span class="hljs-literal">nil</span> &#123;        <span class="hljs-keyword">return</span> root    &#125;           <span class="hljs-keyword">for</span> leftNode:= root;leftNode!=<span class="hljs-literal">nil</span>;&#123;        <span class="hljs-keyword">var</span> firstChild *Node        <span class="hljs-keyword">for</span> curNode := leftNode;curNode != <span class="hljs-literal">nil</span>;curNode = curNode.Next&#123;            <span class="hljs-keyword">if</span> curNode.Left != <span class="hljs-literal">nil</span>&#123;                <span class="hljs-keyword">if</span> curNode.Right != <span class="hljs-literal">nil</span>&#123;                    curNode.Left.Next=curNode.Right;                &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> curNode.Next != <span class="hljs-literal">nil</span> &#123;                    curNode.Left.Next=findLeftestNode(curNode.Next)                &#125;                <span class="hljs-keyword">if</span> firstChild == <span class="hljs-literal">nil</span>&#123;                    firstChild = curNode.Left                &#125;            &#125;            <span class="hljs-keyword">if</span> curNode.Right != <span class="hljs-literal">nil</span> &#123;                <span class="hljs-keyword">if</span> curNode.Next != <span class="hljs-literal">nil</span>&#123;                     curNode.Right.Next = findLeftestNode(curNode.Next)                &#125;                <span class="hljs-keyword">if</span> firstChild == <span class="hljs-literal">nil</span>&#123;                    firstChild = curNode.Right                &#125;            &#125;        &#125;        leftNode = firstChild    &#125;<span class="hljs-keyword">return</span> root&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">findLeftestNode</span><span class="hljs-params">(root *Node)</span> *<span class="hljs-title">Node</span></span>&#123;    <span class="hljs-keyword">for</span> curNode:= root; curNode != <span class="hljs-literal">nil</span> ;curNode = curNode.Next&#123;        <span class="hljs-keyword">if</span> curNode.Left != <span class="hljs-literal">nil</span>&#123;            <span class="hljs-keyword">return</span> curNode.Left        &#125;        <span class="hljs-keyword">if</span> curNode.Right != <span class="hljs-literal">nil</span>&#123;            <span class="hljs-keyword">return</span> curNode.Right        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
      <category>LeetCode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>BFS</tag>
      
      <tag>二叉树</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>每天一题 LeetCode81 Search in Rotated Sorted Array II</title>
    <link href="/2020/10/13/%E6%AF%8F%E5%A4%A9%E4%B8%80%E9%A2%98-LeetCode81-Search-in-Rotated-Sorted-Array-II/"/>
    <url>/2020/10/13/%E6%AF%8F%E5%A4%A9%E4%B8%80%E9%A2%98-LeetCode81-Search-in-Rotated-Sorted-Array-II/</url>
    
    <content type="html"><![CDATA[<p>特殊情况的二分算法。</p><a id="more"></a><h1 id="每天一题-LeetCode81-Search-in-Rotated-Sorted-Array-II"><a href="#每天一题-LeetCode81-Search-in-Rotated-Sorted-Array-II" class="headerlink" title="每天一题 LeetCode81 Search in Rotated Sorted Array II"></a>每天一题 LeetCode81 Search in Rotated Sorted Array II</h1><h2 id="1-题目"><a href="#1-题目" class="headerlink" title="1. 题目"></a>1. 题目</h2><p><a href="https://leetcode.com/problems/search-in-rotated-sorted-array-ii/">https://leetcode.com/problems/search-in-rotated-sorted-array-ii/</a></p><div class="note note-primary">            <p>Suppose an array sorted in ascending order is rotated at some pivot unknown to you beforehand.</p><p>(i.e., [0,0,1,2,2,5,6] might become [2,5,6,0,0,1,2]).</p><p>You are given a target value to search. If found in the array return true, otherwise return false.</p><p>Example 1:</p><pre><code>Input: nums = [2,5,6,0,0,1,2], target = 0Output: true</code></pre><p>Example 2:</p><pre><code>Input: nums = [2,5,6,0,0,1,2], target = 3Output: falseFollow up:</code></pre><ul><li>This is a follow up problem to Search in Rotated Sorted Array, where nums may contain duplicates.</li><li>Would this affect the run-time complexity? How and why?</li></ul>          </div><h2 id="2-解法"><a href="#2-解法" class="headerlink" title="2. 解法"></a>2. 解法</h2><p>使用二分法，mid的位置有三种情况（google绘图，很丑，大概懂意思就行）：</p><table><thead><tr><th>图示</th><th><div style="width: 260pt">指针大小情况</div></th></tr></thead><tbody><tr><td><img src="/img/leetcode/rightmid.png" alt="img"></td><td>nums[mid] &lt;= nums[right] &lt;= nums[left]</td></tr><tr><td><img src="/img/leetcode/leftmid.png" alt="img"></td><td>nums[right] &lt;= nums[left] &lt;= nums[mid]</td></tr><tr><td><img src="/img/leetcode/totalSorted.png" alt="img"></td><td>nums[left] &lt;= nums[mid] &lt;= nums[right]</td></tr></tbody></table><p>再分别在这三种情况里针对target的位置进行判定就行了。<br>代码：</p><pre><code class="hljs go"><span class="hljs-keyword">import</span> <span class="hljs-string">&quot;fmt&quot;</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">search</span><span class="hljs-params">(nums []<span class="hljs-keyword">int</span>, target <span class="hljs-keyword">int</span>)</span> <span class="hljs-title">bool</span></span> &#123;    l, r := <span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(nums) - <span class="hljs-number">1</span>    <span class="hljs-keyword">for</span> l &lt;= r &#123;        <span class="hljs-keyword">for</span> l &lt; r &amp;&amp; nums[l+<span class="hljs-number">1</span>] == nums[l]&#123; <span class="hljs-comment">// 去重</span>            l++        &#125;        <span class="hljs-keyword">for</span> r &gt; l &amp;&amp; nums[r<span class="hljs-number">-1</span>] == nums[r]&#123; <span class="hljs-comment">// 去重</span>            r--        &#125;        m := l + (r - l) / <span class="hljs-number">2</span>        fmt.Println(l,m,r)        <span class="hljs-keyword">switch</span>&#123;        <span class="hljs-keyword">case</span> nums[m] == target :            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>         <span class="hljs-keyword">case</span> nums[m] &lt;= nums[r] &amp;&amp; nums[r] &lt;= nums[l]: <span class="hljs-comment">//mid 在更小的这边</span>            <span class="hljs-keyword">if</span> target &lt; nums[m] || target &gt; nums[r]&#123;                r = m - <span class="hljs-number">1</span>            &#125;<span class="hljs-keyword">else</span>&#123;                l = m + <span class="hljs-number">1</span>            &#125;        <span class="hljs-keyword">case</span> nums[r] &lt;= nums[l] &amp;&amp; nums[l] &lt;= nums[m]: <span class="hljs-comment">//mid 在更大的这边</span>            <span class="hljs-keyword">if</span> target &lt; nums[m] &amp;&amp; target &gt; nums[r]&#123;                r = m - <span class="hljs-number">1</span>            &#125;<span class="hljs-keyword">else</span>&#123;                l = m + <span class="hljs-number">1</span>            &#125;        <span class="hljs-keyword">case</span> nums[l] &lt;= nums[m] &amp;&amp; nums[m] &lt;= nums[r]: <span class="hljs-comment">//l与r之间是顺序</span>            <span class="hljs-keyword">if</span> target &lt; nums[m]&#123;                r = m - <span class="hljs-number">1</span>            &#125;<span class="hljs-keyword">else</span>&#123;                l = m + <span class="hljs-number">1</span>            &#125;        &#125;    &#125;    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>&#125;</code></pre>]]></content>
    
    
    <categories>
      
      <category>算法</category>
      
      <category>LeetCode</category>
      
    </categories>
    
    
    <tags>
      
      <tag>算法</tag>
      
      <tag>二分</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2020 Spring 6.824 Lab2C: Raft State Persist笔记</title>
    <link href="/2020/10/10/2020-Spring-6-824-Lab2C-Raft-State-Persist%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/10/10/2020-Spring-6-824-Lab2C-Raft-State-Persist%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="2020-Spring-6-824-Lab2C-Raft-State-Persist笔记"><a href="#2020-Spring-6-824-Lab2C-Raft-State-Persist笔记" class="headerlink" title="2020 Spring 6.824 Lab2C: Raft State Persist笔记"></a>2020 Spring 6.824 Lab2C: Raft State Persist笔记</h1><h2 id="0-Raft算法基础"><a href="#0-Raft算法基础" class="headerlink" title="0. Raft算法基础"></a>0. Raft算法基础</h2><p>最好先看一遍论文原文：<a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf</a></p><p>这个中文翻译很不错，我的注释代码很多都是参照里面：<a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md">https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md</a></p><p>这个Raft可视化也不错，如果看不下论文可以先看一遍这个：<a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></p><p>本章代码地址：<a href="https://github.com/keleqnma/6.824-notes-codes/tree/master/src/raft">https://github.com/keleqnma/6.824-notes-codes/tree/master/src/raft</a></p>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
      <category>6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2020 Spring 6.824 Lab2B: Raft Log Replication笔记</title>
    <link href="/2020/10/10/2020-Spring-6-824-Lab2B-Raft-Log-Replication%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/10/10/2020-Spring-6-824-Lab2B-Raft-Log-Replication%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>当Leader被选举出来后，将会从客户端接收命令更新日志，leader节点会维护日志条目更新的一致性。本章将实现Lab2B，详细介绍如何实现Raft算法里的Raft Log Replication，以及该部分的可靠性，如何处理乱序，断连等复杂网络情况。</p><a id="more"></a><h1 id="2020-Spring-6-824-Lab2B-Raft-Log-Replication笔记"><a href="#2020-Spring-6-824-Lab2B-Raft-Log-Replication笔记" class="headerlink" title="2020 Spring 6.824 Lab2B: Raft Log Replication笔记"></a>2020 Spring 6.824 Lab2B: Raft Log Replication笔记</h1><h2 id="0-Raft-Log-Replication在干啥"><a href="#0-Raft-Log-Replication在干啥" class="headerlink" title="0. Raft Log Replication在干啥"></a>0. Raft Log Replication在干啥</h2><div class="note note-info">            <p>raft集群接受client的添加log需求，leader需要负责log在集群内部的复制，保证log的有序性，唯一性，在部分节点宕机，网络隔离的情况下仍能保证服务的稳定性。</p><p>raft如何实现？</p><p>用term，log index标识log，并在心跳检查，选举检查时保证leader拥有之前commit的所有log，leader再不断对follower发出心跳对follower复制log。</p>          </div><p>最好先看一遍论文原文：<a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf</a></p><p>这个中文翻译很不错，我的注释代码很多都是参照里面：<a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md">https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md</a></p><p>这个Raft可视化也不错，如果看不下论文可以先看一遍这个：<a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></p><p>本章代码地址：<a href="https://github.com/keleqnma/6.824-notes-codes/tree/master/src/raft">https://github.com/keleqnma/6.824-notes-codes/tree/master/src/raft</a></p><p>我还是建议想学6.824的同学仔仔细细去看一遍论文原文，之前我看了一些文章，搞懂了Raft大致是什么原理，怎么工作的，但是要实现它必须还是要去看原文，有很多细节需要注意。</p><h2 id="1-测试代码"><a href="#1-测试代码" class="headerlink" title="1. 测试代码"></a>1. 测试代码</h2><p>测试代码初始化我已经在2A中讲过了，这里不再讲，这里大概讲一下2B的测试都是测试什么情况。</p><p>2B的测试很多，有八个。</p><p>2B要求保证集群接受log，leader用appendEntries在集群里同步log，并要求leader，follower宕机的情况下也可以保证服务稳定性。</p><table><thead><tr><th>测试</th><th>测试内容</th><th>错误情况</th></tr></thead><tbody><tr><td>TestBasicAgree2B</td><td>简单的提交的一个log，然后检查各个raft server关于该log有没有达成一致</td><td></td></tr><tr><td>TestRPCBytes2B</td><td>检查log在没有断联的情况下有没有重发/多发。</td><td>1.心跳间隔设置太短会出现过不了的情况，建议按照论文推荐设置，150ms，tester限制一秒至多十次心跳。2.leader向follow发送rpc后等待回信的时候，可能会超时，这时候可能会重发，这里可以加一个计时器，或者加一个channel，表示正在发送，不需要启动额外的重发。</td></tr><tr><td>TestFailAgree2B</td><td>测试少数（1/3）的节点失败重连时的系统情况</td><td>占多数节点的网络内部正常，少数断联节点内部无法选举出一个新Leader，term不断增加，重连后term比其他节点都大，却又没有正确的log，其他节点拒绝投票，导致整个系统内部无法选出Leader。</td></tr><tr><td>TestFailNoAgree2B</td><td>测试一半以上（3/5）的节点失败重连时的系统情况</td><td>如上。</td></tr><tr><td>TestConcurrentStarts2B</td><td>检查并发向raft准备同步的日志里提交的情况</td><td></td></tr><tr><td>TestRejoin2B</td><td>老leader断联后自己收了一大堆log，新leader也收一大堆log（和老leader不一致），然后重连老leader，检查是否正常。</td><td></td></tr><tr><td>TestBackup2B</td><td>检查日志同步能力。不断disconnect不同的leader，一下子disconnect大多数导致集群崩溃，一下子connect回来导致集群恢复，主要是考察复杂网络情况下raft算法能不能保证数据同步的快速性稳定性。</td><td>非常多，包含大量的随机性。</td></tr><tr><td>TestCount2B</td><td>主要还是检验完成整个集群的commit需要的时间和RPC次数，以及没有网络隔离情况下leader和term是否有变化。</td><td></td></tr></tbody></table><h2 id="2-结构定义"><a href="#2-结构定义" class="headerlink" title="2. 结构定义"></a>2. 结构定义</h2><p><img src="/img/raft/AppendEntriesRPC.png" alt="img"><br>代码：</p><pre><code class="hljs go"><span class="hljs-keyword">type</span> AppendEntriesArgs <span class="hljs-keyword">struct</span> &#123;Term         <span class="hljs-keyword">int</span>LeaderId     <span class="hljs-keyword">int</span>PrevLogIndex <span class="hljs-keyword">int</span>        <span class="hljs-comment">//紧邻需要添加的新日志条目之前的那个日志条目的索引</span>PrevLogTerm  <span class="hljs-keyword">int</span>        <span class="hljs-comment">//紧邻需要添加的新日志条目之前的那个日志条目的任期</span>Entries      []LogEntry <span class="hljs-comment">//需要被保存的日志条目（被当做心跳使用时日志条目内容为空；为了提高效率可能一次性发送多个）</span>LeaderCommit <span class="hljs-keyword">int</span>        <span class="hljs-comment">//Ledaer已知已提交的最高的日志条目的索引</span>&#125;<span class="hljs-keyword">type</span> AppendEntriesReply <span class="hljs-keyword">struct</span> &#123;Term      <span class="hljs-keyword">int</span>  <span class="hljs-comment">// 当前服务器的term</span>Success   <span class="hljs-keyword">bool</span> <span class="hljs-comment">// 是否成功</span>NextIndex <span class="hljs-keyword">int</span> <span class="hljs-comment">// 副本主动报告自己需要更新的log index， raft论文里说这种优化没必要，“在实践中，我们十分怀疑这种优化是否是必要的，因为失败是很少发生的并且也不大可能会有这么多不一致的日志。”，但是6.824的模拟环境里就是有这么多，所以需要实现这个优化。</span>&#125;</code></pre><h2 id="3-逻辑实现"><a href="#3-逻辑实现" class="headerlink" title="3. 逻辑实现"></a>3. 逻辑实现</h2><h3 id="3-1-启动AppendEntries"><a href="#3-1-启动AppendEntries" class="headerlink" title="3.1. 启动AppendEntries"></a>3.1. 启动AppendEntries</h3><p>appendEntriesLoop是raft的三大时间驱动Loop之一，要求每个心跳间隔发送一次心跳（如果没有需要同步的log就是心跳）。</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">applyLogLoop</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">for</span> &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-rf.stopCh:<span class="hljs-keyword">return</span><span class="hljs-keyword">case</span> &lt;-rf.applyTimer.C:rf.notifyApplyCh &lt;- <span class="hljs-keyword">struct</span>&#123;&#125;&#123;&#125;<span class="hljs-keyword">case</span> &lt;-rf.notifyApplyCh:rf.startApplyLogs()&#125;&#125;&#125;</code></pre><h3 id="3-2-接收AppendEntries"><a href="#3-2-接收AppendEntries" class="headerlink" title="3.2. 接收AppendEntries"></a>3.2. 接收AppendEntries</h3><ol><li>如果发送方的term小于接受方的term，拒绝添加，<strong>返回</strong>。</li><li>发送方的term大于等于于接受方的term，重置选举计时器，并且重置接收方为follower。</li><li>如果 AppendEntriesArgs.PrevLogIndex（发送方认为接收方已经添加的最后的log index） &gt; 当前接收方最后的log index，中间的log缺失，接收方找到自己需要添加的第一位log index，<strong>返回</strong>。</li><li>发送方发送的log乱序，term没变，但是需要添加的log比当前最后一位log小，<strong>返回</strong>。</li><li>发送方的log记录和接收方记录矛盾（同样的log index，log term不一致），计算自己需要回退到的位置，<strong>返回</strong>。</li><li>记录一致，匹配正常，<strong>添加log</strong>。</li></ol><pre><code class="hljs go"><span class="hljs-comment">// 如果发送方的term小于当前term，拒绝添加</span><span class="hljs-keyword">if</span> rf.currentTerm &gt; args.Term &#123;rf.unlock(<span class="hljs-string">&quot;append_entries&quot;</span>)<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 接收到appendentries后重置选举计时器，并且重置角色</span>rf.currentTerm = args.Termrf.changeRole(Follower)rf.resetElectionTimer()_, lastLogIndex := rf.lastLogTermIndex()<span class="hljs-keyword">switch</span> &#123;<span class="hljs-keyword">case</span> args.PrevLogIndex &gt; lastLogIndex:<span class="hljs-comment">// 缺少中间的 log</span>reply.Success = <span class="hljs-literal">false</span>        <span class="hljs-comment">// 这里没有让leader采取回退政策，而是直接计算告诉leader下一次应该从哪里发送日志（直接把当前最后一条log index返回）</span>reply.NextIndex = rf.getNextIndex()<span class="hljs-keyword">case</span> rf.logEntries[rf.getRealIdxByLogIndex(args.PrevLogIndex)].Term == args.PrevLogTerm:<span class="hljs-keyword">if</span> rf.outOfOrderAppendEntries(args) &#123;reply.Success = <span class="hljs-literal">false</span>reply.NextIndex = <span class="hljs-number">0</span>&#125; <span class="hljs-keyword">else</span> &#123;reply.Success = <span class="hljs-literal">true</span>rf.logEntries = <span class="hljs-built_in">append</span>(rf.logEntries[<span class="hljs-number">0</span>:rf.getRealIdxByLogIndex(args.PrevLogIndex)+<span class="hljs-number">1</span>], args.Entries...)reply.NextIndex = rf.getNextIndex()&#125;<span class="hljs-keyword">default</span>:rf.log(<span class="hljs-string">&quot;prev log not match&quot;</span>)reply.Success = <span class="hljs-literal">false</span><span class="hljs-comment">// 跳过一个 term</span>·····        term := rf.logEntries[args.PrevLogIndex].Term        idx := args.PrevLogIndex        <span class="hljs-keyword">for</span> idx &gt; rf.commitIndex &amp;&amp; rf.logEntries[idx].Term == term &#123;idx -= <span class="hljs-number">1</span>&#125;        <span class="hljs-comment">// 上一个term不一致，就直接跳过上一个term，返回上上个term的log index，从那里开始添加</span>reply.NextIndex = idx + <span class="hljs-number">1</span>&#125;</code></pre><h3 id="3-3-发送AppendEntries"><a href="#3-3-发送AppendEntries" class="headerlink" title="3.3. 发送AppendEntries"></a>3.3. 发送AppendEntries</h3><ol><li><p>检查是否有正在发送AppendEntries的（这里我用了锁，不是很好，可能会大量block goroutine，后续会更改）。如果有正在发送的，<strong>返回。</strong></p></li><li><p>发送AppendEntriesRPC，等待一个随机的RPC timeout，如果计时器结束前没有返回，一直重发直到收到回复。</p></li><li><p>收到回复，开始检查：</p><ol><li>现在当前节点已不再是leader，或者term发生了变化，<strong>返回</strong>。</li><li>目标节点的term比现在leader高（可能是因为网络隔离导致的），重置当前角色为follower，改变term，重置选举计时器，<strong>返回。</strong></li><li>返回失败，重置nextIndex，再次发送。</li><li>返回成功，同步一下已经复制的log位置，并且尝试commit。（一个log被超过半数的节点成功写入，则可以判断是成功commit了）</li></ol></li></ol><h2 id="4-算法可靠性-amp-一致性分析"><a href="#4-算法可靠性-amp-一致性分析" class="headerlink" title="4. 算法可靠性&amp;一致性分析"></a>4. 算法可靠性&amp;一致性分析</h2><p>一系列限制保证了log的可靠性和一致性。</p><ul><li><strong>Raft保证所有之前的任期号中已经提交的日志条目在选举的时候都会出现在Leader中</strong>，不需要传送这些日志条目给Leader。这意味着日志条目的传送是单向的，只从Leader传给follower，并且Leader从不会覆盖自身本地日志中已经存在的条目。</li></ul><blockquote><p>RequestVoteRPC 有这样的限制：RPC 中包含了候选人的日志信息，投票人会拒绝掉那些日志没有自己新的投票请求。<br>Raft 通过比较两份日志中最后一条日志条目的索引值和任期号定义谁的日志比较新。如果两份日志最后的条目的任期号不同，那么任期号大的日志更加新。如果两份日志最后的条目任期号相同，那么日志比较长的那个就更加新。</p></blockquote><ul><li>当Leader复制之前任期里的日志时，Raft 会为所有日志保留<strong>原始</strong>的任期号, 这在提交规则上产生了额外的复杂性。在其他的一致性算法中，如果一个新Leader要重新复制之前的任期里的日志时，它必须使用当前新的任期号。Raft 使用的方法更加容易辨别出日志，因为它可以随着时间和日志的变化对日志维护着同一个任期编号。另外，和其他的算法相比，Raft 中的新Leader只需要发送更少日志条目（其他算法中必须在他们被提交之前发送更多的冗余日志条目来为他们重新编号）。</li></ul>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
      <category>6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2020 Spring 6.824 Lab2A: Raft Leader Election笔记</title>
    <link href="/2020/09/30/2020-Spring-6-824-Lab2A-Raft-Leader-Election%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/09/30/2020-Spring-6-824-Lab2A-Raft-Leader-Election%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>Raft 使用一种心跳机制来触发Leader Election，通过选举一个Leader，然后给予他全部的管理复制日志的权力来实现一致性。本章将实现Lab2A，详细介绍如何实现Raft算法里的Leader Election，以及该部分的可靠性。</p><a id="more"></a><h1 id="2020-Spring-6-824-Lab2A-Raft-Leader-Election笔记"><a href="#2020-Spring-6-824-Lab2A-Raft-Leader-Election笔记" class="headerlink" title="2020 Spring 6.824 Lab2A:Raft Leader Election笔记"></a>2020 Spring 6.824 Lab2A:Raft Leader Election笔记</h1><h2 id="0-Lab2A要干啥"><a href="#0-Lab2A要干啥" class="headerlink" title="0. Lab2A要干啥"></a>0. Lab2A要干啥</h2><ul><li>我们要解决什么问题？</li></ul><p>一致性共识问题。</p><ul><li>采用了什么方案。</li></ul><p>拜占庭方案，Raft改编自Paxos算法，为了解决Paxos难于理解且难于实现的问题。</p><p>先看一遍论文原文：<a href="https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf">https://pdos.csail.mit.edu/6.824/papers/raft-extended.pdf</a></p><p>这个中文翻译很不错，我的注释很多都是参照里面：<a href="https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md">https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md</a></p><p>这个Raft可视化也不错，如果看不下论文可以先看一遍这个：<a href="http://thesecretlivesofdata.com/raft/">http://thesecretlivesofdata.com/raft/</a></p><p>本章代码地址：<a href="https://github.com/keleqnma/6.824-notes-codes/tree/master/src/raft">https://github.com/keleqnma/6.824-notes-codes/tree/master/src/raft</a></p><p>我还是建议想学6.824的同学仔仔细细去看一遍论文原文，之前我看了一些文章，搞懂了Raft大致是什么原理，怎么工作的，但是要实现它必须还是要去看原文，有很多细节需要注意。</p><h2 id="1-测试代码-amp-Config代码逻辑"><a href="#1-测试代码-amp-Config代码逻辑" class="headerlink" title="1. 测试代码&amp;Config代码逻辑"></a>1. 测试代码&amp;Config代码逻辑</h2><h3 id="1-1-测试Config初始化"><a href="#1-1-测试Config初始化" class="headerlink" title="1.1. 测试Config初始化"></a>1.1. 测试Config初始化</h3><p>2A总共有两个test，现在以test2A为例说一下raft的初始化</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestInitialElection2A</span><span class="hljs-params">(t *testing.T)</span></span> &#123;servers := <span class="hljs-number">3</span>cfg := make_config(t, servers, <span class="hljs-literal">false</span>)<span class="hljs-keyword">defer</span> cfg.cleanup()······&#125;</code></pre><p>测试代码注册了一个config（传入参数为3），config注册了三个Raft节点，并完成一系列初始化操作：初始化RPCNet，初始化ApplyErr（对应节点在接收commit时报的错），初始化logs(用于存储key-value结构的Entry数据），连接状态等等，比如这个启动Raft节点的代码：</p><pre><code class="hljs go"><span class="hljs-comment">//</span><span class="hljs-comment">// start or re-start a Raft.</span><span class="hljs-comment">// if one already exists, &quot;kill&quot; it first.</span><span class="hljs-comment">// allocate new outgoing port file names, and a new</span><span class="hljs-comment">// state persister, to isolate previous instance of</span><span class="hljs-comment">// this server. since we cannot really kill it.</span><span class="hljs-comment">//</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(cfg *config)</span> <span class="hljs-title">start1</span><span class="hljs-params">(i <span class="hljs-keyword">int</span>)</span></span> &#123;cfg.crash1(i)<span class="hljs-comment">// a fresh set of outgoing ClientEnd names.</span><span class="hljs-comment">// so that old crashed instance&#x27;s ClientEnds can&#x27;t send.</span>cfg.endnames[i] = <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">string</span>, cfg.n)<span class="hljs-keyword">for</span> j := <span class="hljs-number">0</span>; j &lt; cfg.n; j++ &#123;cfg.endnames[i][j] = randstring(<span class="hljs-number">20</span>)&#125;<span class="hljs-comment">// a fresh set of ClientEnds.</span>ends := <span class="hljs-built_in">make</span>([]*labrpc.ClientEnd, cfg.n)<span class="hljs-keyword">for</span> j := <span class="hljs-number">0</span>; j &lt; cfg.n; j++ &#123;ends[j] = cfg.net.MakeEnd(cfg.endnames[i][j])cfg.net.Connect(cfg.endnames[i][j], j)&#125;cfg.mu.Lock()<span class="hljs-comment">// a fresh persister, so old instance doesn&#x27;t overwrite</span><span class="hljs-comment">// new instance&#x27;s persisted state.</span><span class="hljs-comment">// but copy old persister&#x27;s content so that we always</span><span class="hljs-comment">// pass Make() the last persisted state.</span><span class="hljs-keyword">if</span> cfg.saved[i] != <span class="hljs-literal">nil</span> &#123;cfg.saved[i] = cfg.saved[i].Copy()&#125; <span class="hljs-keyword">else</span> &#123;cfg.saved[i] = MakePersister()&#125;cfg.mu.Unlock()<span class="hljs-comment">// listen to messages from Raft indicating newly committed messages.</span>applyCh := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">chan</span> ApplyMsg)<span class="hljs-keyword">go</span> <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">for</span> m := <span class="hljs-keyword">range</span> applyCh &#123;err_msg := <span class="hljs-string">&quot;&quot;</span><span class="hljs-keyword">if</span> m.CommandValid == <span class="hljs-literal">false</span> &#123;<span class="hljs-comment">// ignore other types of ApplyMsg</span>&#125; <span class="hljs-keyword">else</span> &#123;v := m.Commandcfg.mu.Lock()<span class="hljs-keyword">for</span> j := <span class="hljs-number">0</span>; j &lt; <span class="hljs-built_in">len</span>(cfg.logs); j++ &#123;<span class="hljs-keyword">if</span> old, oldok := cfg.logs[j][m.CommandIndex]; oldok &amp;&amp; old != v &#123;<span class="hljs-comment">// some server has already committed a different value for this entry!</span>err_msg = fmt.Sprintf(<span class="hljs-string">&quot;commit index=%v server=%v %v != server=%v %v&quot;</span>,m.CommandIndex, i, m.Command, j, old)&#125;&#125;_, prevok := cfg.logs[i][m.CommandIndex<span class="hljs-number">-1</span>]cfg.logs[i][m.CommandIndex] = v<span class="hljs-keyword">if</span> m.CommandIndex &gt; cfg.maxIndex &#123;cfg.maxIndex = m.CommandIndex&#125;cfg.mu.Unlock()<span class="hljs-keyword">if</span> m.CommandIndex &gt; <span class="hljs-number">1</span> &amp;&amp; prevok == <span class="hljs-literal">false</span> &#123;err_msg = fmt.Sprintf(<span class="hljs-string">&quot;server %v apply out of order %v&quot;</span>, i, m.CommandIndex)&#125;&#125;<span class="hljs-keyword">if</span> err_msg != <span class="hljs-string">&quot;&quot;</span> &#123;log.Fatalf(<span class="hljs-string">&quot;apply error: %v\n&quot;</span>, err_msg)cfg.applyErr[i] = err_msg<span class="hljs-comment">// keep reading after error so that Raft doesn&#x27;t block</span><span class="hljs-comment">// holding locks...</span>&#125;&#125;&#125;()rf := Make(ends, i, cfg.saved[i], applyCh)cfg.mu.Lock()cfg.rafts[i] = rfcfg.mu.Unlock()svc := labrpc.MakeService(rf)srv := labrpc.MakeServer()srv.AddService(svc)cfg.net.AddServer(i, srv)&#125;</code></pre><p>首先在RPCNet里注册当前节点和其他节点的连接(ends)，并初始化Persister（用于存储raftstate和snapshot的），启动一个Goroutine监听，把监听到的数据和cfg上其他节点进行对比，如果不一样就报错，然后对比commit的序号，如果不符就报错，并且把错误记录进ApplyErr。<br>随后创建一个RaftServer，创建Server的具体代码如下(这也是我们要实现的地方）：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Make</span><span class="hljs-params">(peers []*labrpc.ClientEnd, me <span class="hljs-keyword">int</span>,</span></span><span class="hljs-function"><span class="hljs-params">persister *Persister, applyCh <span class="hljs-keyword">chan</span> ApplyMsg)</span> *<span class="hljs-title">Raft</span></span> &#123;rf := &amp;Raft&#123;&#125;rf.peers = peersrf.persister = persisterrf.me = me<span class="hljs-comment">// Your initialization code here (2A, 2B, 2C).</span><span class="hljs-comment">// initialize from state persisted before a crash</span>rf.readPersist(persister.ReadRaftState())<span class="hljs-keyword">return</span> rf&#125;</code></pre><p>随后用raft server初始化一个service，初始化一个空server，把该service添加到server里，再在RPCNet里添加该Server。</p><h3 id="1-2-测试要点"><a href="#1-2-测试要点" class="headerlink" title="1.2. 测试要点"></a>1.2. 测试要点</h3><p>2A的测试比较简单，只有两个。<br>TestA是检测初始化之后有没有顺利选举出一个Leader，检测term的变化（选举出新Leader后term要加一），然后检测在网络情况不变的情况下，原有Leader有没有被罢黜，term有没有变化：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestInitialElection2A</span><span class="hljs-params">(t *testing.T)</span></span> &#123;servers := <span class="hljs-number">3</span>cfg := make_config(t, servers, <span class="hljs-literal">false</span>)<span class="hljs-keyword">defer</span> cfg.cleanup()cfg.begin(<span class="hljs-string">&quot;Test (2A): initial election&quot;</span>)<span class="hljs-comment">// is a leader elected?</span>cfg.checkOneLeader()<span class="hljs-comment">// sleep a bit to avoid racing with followers learning of the</span><span class="hljs-comment">// election, then check that all peers agree on the term.</span>time.Sleep(<span class="hljs-number">50</span> * time.Millisecond)term1 := cfg.checkTerms()<span class="hljs-keyword">if</span> term1 &lt; <span class="hljs-number">1</span> &#123;t.Fatalf(<span class="hljs-string">&quot;term is %v, but should be at least 1&quot;</span>, term1)&#125;<span class="hljs-comment">// does the leader+term stay the same if there is no network failure?</span>time.Sleep(<span class="hljs-number">2</span> * RaftElectionTimeout)term2 := cfg.checkTerms()<span class="hljs-keyword">if</span> term1 != term2 &#123;fmt.Printf(<span class="hljs-string">&quot;warning: term changed even though there were no failures&quot;</span>)&#125;<span class="hljs-comment">// there should still be a leader.</span>cfg.checkOneLeader()cfg.end()&#125;</code></pre><p>TestB是检测初始化之后有没有顺利选举出一个Leader，然后把原有的Leader断连，检测有没有选举出新Leader，然后再把原有的Leader重连，看看会不会产生两个Leader，然后把包括leader在内的两个节点断连，看看是不是无leader产生（raft算法只能在大多数节点正常工作的情况下运行），再重新连接回两个断连的节点，检测有没有选举出新Leader：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">TestReElection2A</span><span class="hljs-params">(t *testing.T)</span></span> &#123;servers := <span class="hljs-number">3</span>cfg := make_config(t, servers, <span class="hljs-literal">false</span>)<span class="hljs-keyword">defer</span> cfg.cleanup()cfg.begin(<span class="hljs-string">&quot;Test (2A): election after network failure&quot;</span>)leader1 := cfg.checkOneLeader()<span class="hljs-comment">// if the leader disconnects, a new one should be elected.</span>cfg.disconnect(leader1)cfg.checkOneLeader()<span class="hljs-comment">// if the old leader rejoins, that shouldn&#x27;t</span><span class="hljs-comment">// disturb the new leader.</span>cfg.connect(leader1)leader2 := cfg.checkOneLeader()<span class="hljs-comment">// if there&#x27;s no quorum, no leader should</span><span class="hljs-comment">// be elected.</span>cfg.disconnect(leader2)cfg.disconnect((leader2 + <span class="hljs-number">1</span>) % servers)time.Sleep(<span class="hljs-number">2</span> * RaftElectionTimeout)cfg.checkNoLeader()<span class="hljs-comment">// if a quorum arises, it should elect a leader.</span>cfg.connect((leader2 + <span class="hljs-number">1</span>) % servers)cfg.checkOneLeader()<span class="hljs-comment">// re-join of last node shouldn&#x27;t prevent leader from existing.</span>cfg.connect(leader2)cfg.checkOneLeader()cfg.end()&#125;</code></pre><h2 id="2-定义结构"><a href="#2-定义结构" class="headerlink" title="2. 定义结构"></a>2. 定义结构</h2><h3 id="2-1-Raft-State"><a href="#2-1-Raft-State" class="headerlink" title="2.1. Raft State"></a>2.1. Raft State</h3><p><img src="/img/raft/RaftState.png" alt="img"></p><pre><code class="hljs awk">type Raft struct &#123;mu        sync.Mutex          <span class="hljs-regexp">//</span> lock to protect shared access to this pee<span class="hljs-string">r&#x27;s state</span><span class="hljs-string">peers     []*labrpc.ClientEnd // RPC end points of all peers</span><span class="hljs-string">persister *Persister          // Object to hold this peer&#x27;</span>s persisted stateme        int                 <span class="hljs-regexp">//</span> this pee<span class="hljs-string">r&#x27;s index into peers[]</span><span class="hljs-string">dead      int32               // set by Kill()</span><span class="hljs-string"></span><span class="hljs-string">// Your data here (2A, 2B, 2C).</span><span class="hljs-string">// Look at the paper&#x27;</span>s Figure <span class="hljs-number">2</span> <span class="hljs-keyword">for</span> a description of what<span class="hljs-regexp">//</span> state a Raft server must maintain.role        Role <span class="hljs-regexp">//</span>当前服务器的角色currentTerm int  <span class="hljs-regexp">//</span>服务器已知最新的任期（在服务器首次启动的时候初始化为<span class="hljs-number">0</span>，单调递增）electionTimer       *time.Timer   <span class="hljs-regexp">//</span> 发起选举的计时器appendEntriesTimers []*time.Timer <span class="hljs-regexp">//</span> appendEntries的计时器，<span class="hljs-number">2</span>A中用来发心跳applyTimer          *time.Timer   <span class="hljs-regexp">//</span> apply日志的计时器，<span class="hljs-number">2</span>A用不到notifyApplyCh       chan struct&#123;&#125;stopCh              chan struct&#123;&#125;voteFor             int <span class="hljs-regexp">//</span> 当前任期内收到选票的候选者idapplyCh             chan ApplyMsglogEntries  []LogEntry <span class="hljs-regexp">//</span> 日志条目;每个条目包含了用于状态机的命令，以及领导者接收到该条目时的任期（第一个索引为<span class="hljs-number">1</span>）,lastSnapshot 放到 index <span class="hljs-number">0</span>commitIndex int        <span class="hljs-regexp">//</span> 已知已提交的最高的日志条目的索引（初始值为<span class="hljs-number">0</span>，单调递增）lastApplied int        <span class="hljs-regexp">//</span> 已经被应用到状态机的最高的日志条目的索引（初始值为<span class="hljs-number">0</span>，单调递增）<span class="hljs-regexp">//</span>leader需要保存的nextIndex  []int <span class="hljs-regexp">//</span> 对于每一台服务器，发送到该服务器的下一个日志条目的索引（初始值为领导者最后的日志条目的索引+<span class="hljs-number">1</span>）matchIndex []int <span class="hljs-regexp">//</span> 对于每一台服务器，已知的已经复制到该服务器的最高日志条目的索引（初始值为<span class="hljs-number">0</span>，单调递增）lastSnapshotIndex int <span class="hljs-regexp">//</span> 快照中的 indexlastSnapshotTerm  int&#125;</code></pre><h3 id="2-2-RequestVote-RPC"><a href="#2-2-RequestVote-RPC" class="headerlink" title="2.2 RequestVote RPC"></a>2.2 RequestVote RPC</h3><p><img src="/img/raft/RequestVoteRPC.png" alt="img"></p><pre><code class="hljs go"><span class="hljs-keyword">type</span> RequestVoteArgs <span class="hljs-keyword">struct</span> &#123;<span class="hljs-comment">// Your data here (2A, 2B).</span>Term         <span class="hljs-keyword">int</span> <span class="hljs-comment">//候选人的任期号</span>CandidateId  <span class="hljs-keyword">int</span> <span class="hljs-comment">// 请求选票的候选人的 Id</span>LastLogIndex <span class="hljs-keyword">int</span> <span class="hljs-comment">// 候选人的最后日志条目的索引值</span>LastLogTerm  <span class="hljs-keyword">int</span> <span class="hljs-comment">// 候选人最后日志条目的任期号</span>&#125;<span class="hljs-keyword">type</span> RequestVoteReply <span class="hljs-keyword">struct</span> &#123;<span class="hljs-comment">// Your data here (2A).</span>Term        <span class="hljs-keyword">int</span>  <span class="hljs-comment">// 当前任期号，以便于候选人去更新自己的任期号</span>VoteGranted <span class="hljs-keyword">bool</span> <span class="hljs-comment">// 候选人赢得了此张选票时为真</span>&#125;</code></pre><h2 id="3-逻辑实现"><a href="#3-逻辑实现" class="headerlink" title="3. 逻辑实现"></a>3. 逻辑实现</h2><h3 id="3-1-Raft初始化"><a href="#3-1-Raft初始化" class="headerlink" title="3.1. Raft初始化"></a>3.1. Raft初始化</h3><p><img src="/img/raft/ServerStateMachine.png" alt="img"><br><img src="/img/raft/Rules.png" alt="img"><br>每个Raft Server初始化时都是Follower状态，term为0.<br>Raft server初始化一个electionTimer计时器（时间从150ms-300ms不等），如果在计时器完成之前，收到了Candidate服务器发送的投票请求（RequestVote），或者是收到了leader发送的心跳（AppendEntries），则刷新计时器，继续维持Follower状态。<br>如果没有收到，即<strong>选举超时</strong>，则转变为Candidate，发起投票。<br>这里和大多数人一样，将选举计时行为封装为一个loop（raft共有三个loop，electionLoop，appendEntriesLoop，applyLogLoop，这三个时间都是由超时驱动的）。</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(rf *Raft)</span> <span class="hljs-title">electionLoop</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">for</span> &#123;<span class="hljs-keyword">select</span> &#123;<span class="hljs-keyword">case</span> &lt;-rf.stopCh:<span class="hljs-keyword">return</span><span class="hljs-keyword">case</span> &lt;-rf.electionTimer.C:rf.startElection()&#125;&#125;&#125;</code></pre><h3 id="3-2-发起选举，选出Leader"><a href="#3-2-发起选举，选出Leader" class="headerlink" title="3.2. 发起选举，选出Leader"></a>3.2. 发起选举，选出Leader</h3><h4 id="3-2-1-发出选举要求"><a href="#3-2-1-发出选举要求" class="headerlink" title="3.2.1. 发出选举要求"></a>3.2.1. 发出选举要求</h4><p>要开始一次选举过程，跟随者先要增加自己的当前任期号并且转换到Candidate。然后它向集群中的其他节点发送<strong>RequestVoteArgs</strong>来给自己投票。直到以下任意发生：</p><ol><li>赢得选举<blockquote><p>当一个候选人从整个集群的大多数服务器节点获得了针对同一个任期号的选票，那么他就赢得了这次选举并成为领导人。每一个服务器最多会对一个任期号投出一张选票，按照先来先服务的原则。要求大多数选票的规则确保了最多只会有一个候选人赢得此次选举。一旦候选人赢得选举，他就立即成为领导人。然后他会向其他的服务器发送心跳消息来建立自己的权威并且阻止新的领导人的产生。</p></blockquote></li><li>其他Raft节点成为Leader<blockquote><p>在等待投票的时候，候选人可能会从其他的服务器接收到声明它是领导人的附加日志项 RPC。如果这个领导人的任期号（包含在此次的 RPC中）不小于候选人当前的任期号，那么候选人会承认领导人合法并回到跟随者状态。 如果此次 RPC 中的任期号比自己小，那么候选人就会拒绝这次的 RPC 并且继续保持候选人状态。</p></blockquote></li><li>No one wins<blockquote><p>如果有多个跟随者同时成为候选人，那么选票可能会被瓜分以至于没有候选人可以赢得大多数人的支持。当这种情况发生的时候，每一个候选人都会超时，然后通过增加当前任期号来开始一轮新的选举。然而，没有其他机制的话，选票可能会被无限的重复瓜分。</p></blockquote></li></ol><p>Raft 算法使用随机选举超时时间的方法来确保很少会发生选票瓜分的情况，就算发生也能很快的解决。为了阻止选票起初就被瓜分，选举超时时间是从一个固定的区间（例如 150-300 毫秒）随机选择。这样可以把服务器都分散开以至于在大多数情况下只有一个服务器会选举超时；然后他赢得选举并在其他服务器超时之前发送心跳包。同样的机制被用在选票瓜分的情况下。每一个候选人在开始一次选举的时候会重置一个<strong>随机的选举超时时间</strong>，然后在超时时间内等待投票的结果；这样减少了在新的选举中另外的选票瓜分的可能性。</p><h4 id="3-2-2-接收选举要求"><a href="#3-2-2-接收选举要求" class="headerlink" title="3.2.2. 接收选举要求"></a>3.2.2. 接收选举要求</h4><pre><code class="hljs go"><span class="hljs-comment">// 选举人的term小于当前服务器的term，拒绝投票</span><span class="hljs-keyword">if</span> req.Term &lt; rf.currentTerm &#123;<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 已经选举成功，拒绝投票</span><span class="hljs-keyword">if</span> rf.role == Leader &#123;<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 已经投票给当前候选人</span><span class="hljs-keyword">if</span> rf.voteFor == req.CandidateId &#123;reply.VoteGranted = <span class="hljs-literal">true</span><span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 如果已经投票，且对象不是当前候选人，拒绝投票</span><span class="hljs-comment">// 但如果当前服务器不是follwer，且选举人的term不小于当前服务器的term，则它会转投给选举人</span><span class="hljs-keyword">if</span> rf.voteFor != voteForNobody &amp;&amp; rf.voteFor != req.CandidateId &amp;&amp; rf.role == Follower &#123;<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 候选人最后一条日志的term小于当前服务器最后一条日志的term, 或者候选人最后一条日志的index小于当前服务器最后一条日志的index（即log记录冲突），拒绝投票</span><span class="hljs-keyword">if</span> lastLogTerm &gt; req.LastLogTerm || (req.LastLogTerm == lastLogTerm &amp;&amp; req.LastLogIndex &lt; lastLogIndex) &#123;<span class="hljs-keyword">return</span>&#125;<span class="hljs-comment">// 将自身的term调整为和候选人一致</span>rf.currentTerm = req.Term<span class="hljs-comment">// 投票给候选人</span>rf.voteFor = req.CandidateIdreply.VoteGranted = <span class="hljs-literal">true</span>rf.changeRole(Follower)   <span class="hljs-comment">// 刷新计时器</span>rf.resetElectionTimer()rf.log(<span class="hljs-string">&quot;vote for:%d&quot;</span>, req.CandidateId)</code></pre><h3 id="3-3-选举完成，Leader发送心跳"><a href="#3-3-选举完成，Leader发送心跳" class="headerlink" title="3.3. 选举完成，Leader发送心跳"></a>3.3. 选举完成，Leader发送心跳</h3><p>2A里其实没啥好说的，实测就算你不写心跳也能过那两个test，算是测试的设计疏漏吧，appendentries我会放到2B里一起讲。</p><h2 id="4-算法可靠性-amp-一致性分析"><a href="#4-算法可靠性-amp-一致性分析" class="headerlink" title="4. 算法可靠性&amp;一致性分析"></a>4. 算法可靠性&amp;一致性分析</h2><h3 id="4-1-Leader节点崩溃"><a href="#4-1-Leader节点崩溃" class="headerlink" title="4.1. Leader节点崩溃"></a>4.1. Leader节点崩溃</h3><p>Leader崩溃后，Follower节点将不再收到心跳，计时器到时后Follower节点会重新进行选举。</p><h3 id="4-2-Follower节点-Candidate节点崩溃"><a href="#4-2-Follower节点-Candidate节点崩溃" class="headerlink" title="4.2. Follower节点/Candidate节点崩溃"></a>4.2. Follower节点/Candidate节点崩溃</h3><p>Leader节点发现发给某个follower节点的心跳超时后，Leader节点会<strong>无限重发</strong>。Raft 的 RPCs 都是<strong>幂等</strong>的，所以这样重试不会造成任何问题。例如一个跟随者如果收到附加日志请求但是他已经包含了这一日志，那么他就会直接忽略这个新的请求。</p><div class="note note-info">            <p><strong>幂等（idempotent、idempotence）</strong>是一个数学与计算机学概念，常见于抽象代数中。<br>在编程中一个幂等操作的特点是<strong>其任意多次执行所产生的影响均与一次执行的影响相同</strong>。幂等函数，或幂等方法，是指可以使用相同参数重复执行，并能获得相同结果的函数。这些函数不会影响系统状态，也不用担心重复执行会对系统造成改变。例如，“setTrue()”函数就是一个幂等函数,无论多次执行，其结果都是一样的，更复杂的操作幂等保证是利用唯一交易号(流水号)实现.</p>          </div><h3 id="4-3-如何保证选出一个稳定的Leader？"><a href="#4-3-如何保证选出一个稳定的Leader？" class="headerlink" title="4.3. 如何保证选出一个稳定的Leader？"></a>4.3. 如何保证选出一个稳定的Leader？</h3><ol><li><p>要求一个Leader只有拿到大于一半节点的投票才能当选，且每个节点在一次任期中只能投给一个Candidate，保证了每次term里只会选出一个Leader。</p></li><li><p>Raft 的要求之一就是安全性不能依赖时间：整个系统不能因为某些事件运行的比预期快一点或者慢一点就产生了错误的结果。但是，可用性（系统可以及时的响应客户端）不可避免的要依赖于时间。例如，如果消息交换比服务器故障间隔时间长，候选人将没有足够长的时间来赢得选举；没有一个稳定的Leader，Raft 将无法工作。<br> 所以我们要保证：</p><blockquote><p>广播时间（broadcastTime） &lt;&lt; 选举超时时间（electionTimeout） &lt;&lt; 平均故障间隔时间（MTBF）</p></blockquote><p> 在这个不等式中，广播时间指的是从一个服务器并行的发送 RPCs 给集群中的其他服务器并接收响应的平均时间；选举超时时间是在 选举的超时时间限制；平均故障间隔时间就是对于一台服务器而言，两次故障之间的平均时间。广播时间必须比选举超时时间小一个量级，这样领导人才能够发送稳定的心跳消息来阻止跟随者开始进入选举状态；通过随机化选举超时时间的方法，这个不等式也使得选票瓜分的情况变得不可能。选举超时时间应该要比平均故障间隔时间小上几个数量级，这样整个系统才能稳定的运行。当领导人崩溃后，整个系统会大约相当于选举超时的时间里不可用；我们希望这种情况在整个系统的运行中很少出现。</p><p> 广播时间和平均故障间隔时间是由系统决定的，但是选举超时时间是我们自己选择的。Raft 的 RPCs 需要接收方将信息持久化的保存到稳定存储中去，所以广播时间大约是 0.5 毫秒到 20 毫秒，取决于存储的技术。因此，选举超时时间可能需要在 10 毫秒到 500 毫秒之间。大多数的服务器的平均故障间隔时间都在几个月甚至更长，很容易满足时间的需求。</p></li></ol>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
      <category>6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
      <tag>6.824</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP详解笔记</title>
    <link href="/2020/09/29/TCP%E8%AF%A6%E8%A7%A3%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/09/29/TCP%E8%AF%A6%E8%A7%A3%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<p>TCP协议详解，重传机制，RTT算法，滑动窗口，拥塞控制等。</p><a id="more"></a><h2 id="0-总述"><a href="#0-总述" class="headerlink" title="0. 总述"></a>0. 总述</h2><p>TCP发展到今天已经是非常成熟的协议了，作为<strong>传输层（Tranport Layer）</strong>协议，可供跨任意网络可靠地传输数据。以TCP端口的形式为应用程序提供传输层寻址（transport-layer addressing），并用这些端口在机器之间建立连接。一旦建立了连接，就可以在两个设备之间<strong>双向</strong>传递数据。应用程序可以将数据作为简单的字节流发送到TCP端口，而TCP协议负责将数据打包为IP报文发送。接收设备的TCP实现将过程逆转，将最初发送的数据流传递给应用程序。</p><p>TCP包含很多机制，以确保数据的可靠性，一致性和及时性。这其中关键是<strong>滑动窗口</strong>，该机制要求每个设备追踪已发送的数据（即要求收到ACK），并确认接收到的数据（收到数据后会发送ACK）。未确认的数据会自动重传，并且可以根据设备和连接的需要调整系统的参数。该系统还提供了设备之间的缓冲和流控制功能，以处理不均匀的数据传输速率和其他问题。</p><p>TCP可以最大程度地满足几乎所有需要<strong>面向连接（connection-oriented）</strong>的<strong>可靠</strong>数据传递需要。这是TCP的主要目标，因为这意味着高层应用程序不必单独提供这些通用功能。 TCP是最广泛使用的TCP / IP传输协议，大多数应用程序都采用TCP。</p><div class="note note-success">            <p>概括一下TCP的<strong>主要特征</strong>：我们可以说它是<strong>面向连接的，双向的，多连接的，可靠的，需要确认的，面向流和流管理的</strong>。</p>          </div><h2 id="1-TCP究竟干了啥？"><a href="#1-TCP究竟干了啥？" class="headerlink" title="1. TCP究竟干了啥？"></a>1. TCP究竟干了啥？</h2><h3 id="1-1-TCP能干啥？"><a href="#1-1-TCP能干啥？" class="headerlink" title="1.1. TCP能干啥？"></a>1.1. TCP能干啥？</h3><ol><li><p><strong>寻址/多路复用：</strong> 像UDP一样，TCP的一项重要工作是多路复用从不同进程接收到的数据，以便可以使用基础网络层协议将其发送出去。</p></li><li><p><strong>连接的建立，管理和终止</strong>：设备可以遵循TCP标准流程来建立可以传输数据的TCP连接。一旦连接建立，TCP就会开始管理该连接以及处理问题。当设备启动关闭TCP连接后，会有一个特殊的TCP进程将此连接中止。</p></li><li><p><strong>数据处理和打包：</strong>TCP定义了一种机制，应用程序可以通过该机制从更高层向其发送数据。然后，将这些数据打包成消息，以发送到目标TCP软件。目标软件将数据打包，然后将其提供给目标计算机上的应用程序。</p></li><li><p><strong>数据传输：</strong>从概念上讲，传输设备上的TCP实现负责将打包的数据传输到另一设备上的TCP进程。遵循分层原理，这是通过使发送机上的TCP软件将数据包传递到基础网络层协议（IP协议）来完成的。</p></li><li><p><strong>提供可靠性和传输质量服务：</strong> 使用TCP协议发送数据是“可靠的”。这意味着，使用TCP不必担心数据没有被发送，数据没有抵达，或以错误的顺序到达。这也意味着避免了直接使用IP协议发送数据可能会出现的其他常见问题。</p></li><li><p><strong>流控制和拥塞避免：</strong>TCP控制和管理两个设备之间的数据流，以及处理通信期间可能遇到的拥塞的。</p></li></ol><h3 id="1-2-TCP不能干啥？"><a href="#1-2-TCP不能干啥？" class="headerlink" title="1.2. TCP不能干啥？"></a>1.2. TCP不能干啥？</h3><ol><li><p><strong>指定应用用途：</strong> TCP没有具体描述应用程序该如何使用TCP。</p></li><li><p><strong>提供安全性：</strong>TCP不提供任何机制来确保其传输的数据的真实性或私密性。如果需要这些，则必须使用其他某种方式来完成，例如IPSec。</p></li><li><p><strong>维护消息边界：</strong>TCP将数据作为连续流而不是离散消息发送。应该由应用程序决定一条消息的结束位置和下一条消息的开始位置。</p></li><li><p><strong>保证通信：</strong>TCP会检测未确认的传输，并在需要时重新发送。但是，如果出现某种问题导致无法可靠通信，则所有TCP可以做的就是“继续尝试”。它无法做出任何保证，因为有太多事情无法控制。同样，它可以尝试管理数据流，但不能解决所有问题。</p></li></ol><h2 id="2-重传机制"><a href="#2-重传机制" class="headerlink" title="2. 重传机制"></a>2. 重传机制</h2><h2 id="3-RTT算法"><a href="#3-RTT算法" class="headerlink" title="3. RTT算法"></a>3. RTT算法</h2><h2 id="4-滑动窗口"><a href="#4-滑动窗口" class="headerlink" title="4. 滑动窗口"></a>4. 滑动窗口</h2><h2 id="5-拥塞控制"><a href="#5-拥塞控制" class="headerlink" title="5. 拥塞控制"></a>5. 拥塞控制</h2><h2 id="6-面试常问问题"><a href="#6-面试常问问题" class="headerlink" title="6. 面试常问问题"></a>6. 面试常问问题</h2><h3 id="6-1-tcp的可靠性如何保证"><a href="#6-1-tcp的可靠性如何保证" class="headerlink" title="6.1. tcp的可靠性如何保证"></a>6.1. tcp的可靠性如何保证</h3><p>分块传送：数据被分割成最合适的数据块（UDP的数据报长度不变）</p><p>等待确认：通过定时器等待接收端发送确认请求，收不到确认则重发</p><p>确认回复：收到确认后发送确认回复(不是立即发送，通常推迟几分之一秒)</p><p>数据校验：保持首部和数据的校验和，检测数据传输过程有无变化</p><p>乱序排序：接收端能重排序数据，以正确的顺序交给应用端</p><p>重复丢弃：接收端能丢弃重复的数据包</p><p>流量缓冲：两端有固定大小的缓冲区（滑动窗口），防止速度不匹配丢数据</p>]]></content>
    
    
    <categories>
      
      <category>计算机网络</category>
      
      <category>TCP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>计算机网络</tag>
      
      <tag>TCP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2020 Spring 6.824 Lab1: MapReduce笔记</title>
    <link href="/2020/09/28/2020-Spring-6-824-Lab1-MapReduce%E7%AC%94%E8%AE%B0/"/>
    <url>/2020/09/28/2020-Spring-6-824-Lab1-MapReduce%E7%AC%94%E8%AE%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="2020-Spring-6-824-Lab1-MapReduce笔记"><a href="#2020-Spring-6-824-Lab1-MapReduce笔记" class="headerlink" title="2020 Spring 6.824 Lab1: MapReduce笔记"></a>2020 Spring 6.824 Lab1: MapReduce笔记</h1><p>本节lab的代码：<a href="https://github.com/keleqnma/6.824-notes-codes/tree/master/src/mr">https://github.com/keleqnma/6.824-notes-codes/tree/master/src/mr</a></p><h2 id="0-MapReduce架构"><a href="#0-MapReduce架构" class="headerlink" title="0. MapReduce架构"></a>0. MapReduce架构</h2><ul><li>集群中的角色分类<ul><li>Master 负责任务调度(分配任务，重新执行，调度等)</li><li>Worker 负责运行 Map 任务 或者 Reduce 任务</li></ul></li><li>worker 运行的任务分类<ul><li>Map 任务： 每个Map 任务读取部分输入 产生中间的<em>k v</em> 数据</li><li>Reduce 任务： 读取map 产生的中间 <em>k v</em> 数据每个Reduce 产出一个输出文件</li></ul></li></ul><p><img src="https://www.talend.com/wp-content/uploads/what-is-mapreduce.jpg" alt="image"></p><p><code>MapReduce</code> 的整体思想是： <strong>将输入的数据分成 M 个 <code>tasks</code>， 由用户自定义的 <code>Map</code> 函数去执行任务，产出 <code>&lt;Key, Value&gt;</code>形式的中间数据，然后相同的 key 通过用户自定义的 <code>Reduce</code> 函数去聚合，得到最终的结果。</strong> </p><ol><li>MapReduce程序负责将用户的输入划分为M块 <code>16M ~ 64M</code> 的块大小。通过划分函数<code>(hash(key) mod R)</code> 会把Map中间数据划分为R个分区。</li><li>将程序复制到集群中的各个需要运行的机器上并启动</li><li>Master 给空闲的机器分配Map 或者Reduce 任务，由于(1) 中说输入文件被划分了M块，分区函数 <code>mod R</code> 所以此时Map任务被划分为了M个任务，Reduce任务被划分了R个分区，同时最终结果也会产生 <code>&lt;= R</code> 个最终输出的文件</li><li>执行Map任务的worker读取相应的输入块,解析后发送给用户自定义的Map程序，用户Map程序将处理后的中间结果保存在内存当中。</li><li>保存在内存中的中间结果会定期的被根据分区函数划分为<code>R个区域</code>写入本地磁盘，本地磁盘保存的<code>位置信息</code>会被传输到Master，Master将这些partation位置信息<code>转发</code>到Reduce 的worker。</li><li>Reduce worker 接收到这些位置信息后会通过<code>RPC调用</code>从Map Worker的磁盘中读取相应partation的中间结果，当Reduce读取了所有的中间结果的之后将<code>按照key进行一次排序</code>，因为多个worker任务产生的中间结果会被同一个Reduce worker 读取,所以为了保证结果有序还需要重新排序一次。</li><li>reduce worker 遍历排序过的中间数据，给每个遇到的唯一的中间key，将这个key和对应的value传递到用户的reduce 方法中。reduce 方法的输出会被添加到这个分区最终输出文件中。</li><li>所有任务结束后会产生<code>R</code>个输出文件，不需要合并。</li></ol><h3 id="Map-过程"><a href="#Map-过程" class="headerlink" title="Map 过程"></a>Map 过程</h3><ul><li>根据输入输入信息，将输入数据 split 成 M 份， 比如上图中的 split0 - split4 <code>(这里M=5)</code></li><li>在所有可用的<code>worker</code>节点中，起 M 个<code>task</code>任务的线程， 每个任务会读取对应一个 split 当做输入。</li><li>调用 <code>map</code> 函数，将输入转化为  <code>&lt;Key, Value&gt;</code> 格式的中间数据，并且排序后，写入磁盘。 这里，每个 <code>task</code> 会写 R 个文件，对应着 <code>Reduce</code> 任务数。 数据写入哪个文件的规则由 <code>Partitioner</code> 决定，默认是 <code>hash(key) % R</code></li><li>(可选) 为了优化性能，中间还可以用一个 <code>combiner</code> 的中间过程</li></ul><h3 id="Reduce-过程"><a href="#Reduce-过程" class="headerlink" title="Reduce 过程"></a>Reduce 过程</h3><ul><li><code>map</code> 阶段结束以后， 开始进入 <code>Reduce</code> 阶段，每个 <code>Reduce task</code>会从所有的 <code>Map</code> 中间数据中，获取属于自己的一份数据，拿到所有数据后，一般会进行排序<code>(Hadoop 框架是这样做)</code>  。</li></ul><blockquote><p>说明： 这个排序是非常必要的，主要因为 <code>Reduce</code> 函数的输入 是  <code>&lt;key, []values&gt;</code>  的格式，因为需要根据key去排序。有同学想为啥不用 <code>map&lt;&gt;()</code> 去实现呢？ 原因：因为map必须存到内存中，但是实际中数据量很大，往往需要溢写到磁盘。 但是排序是可以做到的，比如归并排序。 这也就是map端产出数据需要排序，Reduce端获取数据后也需要先排序的原因。</p></blockquote><ul><li>调用 <code>Reduce</code> 函数，得到最终的结果输出结果，存入对应的文件</li><li>(可选) 汇总所有 <code>Reduce</code>任务的结果。一般不做汇总，因为通常一个任务的结果往往是另一个 <code>MapReduce</code>任务的输入，因此没必要汇总到一个文件中。</li></ul><h2 id="1-Map结构"><a href="#1-Map结构" class="headerlink" title="1.Map结构"></a>1.Map结构</h2><p><code>master</code> 是 <code>MapReduce</code> 任务中最核心的角色，它需要维护 <strong>状态信息</strong> 和 <strong>文件信息</strong>。</p><ul><li>状态信息：<ul><li><code>map</code> 任务状态</li><li><code>Reduce</code> 任务状态</li><li><code>worker</code> 节点状态</li></ul></li><li>文件信息<ul><li>输入文件信息</li><li>输出文件信息</li><li><code>map</code>中间数据文件信息</li></ul></li></ul><h2 id="2-容错"><a href="#2-容错" class="headerlink" title="2. 容错"></a>2. 容错</h2><h3 id="worker-节点失败"><a href="#worker-节点失败" class="headerlink" title="worker 节点失败"></a>worker 节点失败</h3><p><code>master</code>会周期性向所有节点发送<code>ping </code>心跳检测， 如果超时未回复，<code>master</code>会认为该<code>worker</code>已经故障。任何在该节点完成的<code>map </code>或者<code>Reduce</code>任务都会被标记为<code>idle</code>， 并由其他的<code>worker</code> 重新执行。</p><blockquote><p>说明： 因为<code>MapReduce</code> 为了减少网络带宽的消耗，<code>map</code>的数据是存储在本地磁盘的，如果某个<code>worker</code>机器故障，会导致其他的<code>Reduce</code> 任务拿不到对应的中间数据，所以需要重跑任务。那么这也可以看出，如果利用<code>hadoop</code> 等分布式文件系统来存储中间数据，其实对于完成的<code>map</code>任务，是不需要重跑的，代价就是增加网络带宽。</p></blockquote><h3 id="Master-节点失败"><a href="#Master-节点失败" class="headerlink" title="Master 节点失败"></a>Master 节点失败</h3><p><code>master</code>节点失败，在没有实现HA 的情况下，可以说基本整个<code>MapReduce</code>任务就已经挂了，对于这种情况，直接重新启动<code>master</code> 重跑任务就ok了。 当然啦，如果集群有高可靠方案，比如<code>master</code>主副备用，就可以实现<code>master</code>的高可靠，<strong>代价就是得同步维护主副之间的状态信息和文件信息等。</strong></p><h3 id="失败处理"><a href="#失败处理" class="headerlink" title="失败处理"></a>失败处理</h3><p>论文中提到，只要<code>MapReduce</code>函数是确定的，语义上不管是分布式执行还是单机执行，结果都是一致的。每个<code>map</code> <code>Reduce</code> 任务输出是通过原子提交来保证的， 即：</p><p><strong>一个任务要么有完整的最终文件，要么存在最终输出结果，要么不存在。</strong></p><ul><li>每个进行中的任务，在没有最终语义完成之前，都只写临时文件，每个<code>Reduce</code> 任务会写一个，而每个<code>Map</code> 任务会写 R 个，对应 R 个<code>reducer</code>.</li><li>当 <code>Map</code> 任务完成的时候，会向<code>master</code>发送文件位置，大小等信息。<code>Master</code>如果接受到一个已经完成的<code>Map</code>任务的信息，就忽略掉，否则，会记录这个信息。</li><li>当 <code>Reduce</code> 任务完成的时候，会将临时文件重命名为最终的输出文件， 如果多个相同的<code>Reduce</code>任务在多台机器执行完，会多次覆盖输出文件，这个由底层文件系统的<code>rename</code>操作的原子性，保证任何时刻，看到的都是一个完整的成功结果</li></ul><p>对于大部分确定性的任务，不管是分布式还是串行执行，最终都会得到一致的结果。对于不确定的<code>map</code> 或者<code>Reduce</code> 任务，<code>MapReduce</code> 保证提供一个弱的，仍然合理的语义。</p><blockquote><p>举个例子来说:</p><p>确定性任务比如 词频统计   不管你怎么执行，串行或者并行，最终得到的都是确定性的统计结果。</p><p>第二个不确定性任务： 随机传播算法，<code>pageRank</code> 等，因为会有概率因素在里面，也就是说你每次跑的结果数据不一定能对的上。但是是合理的，因为本来就有很多随机的因素在里面。</p></blockquote><h2 id="3-优化"><a href="#3-优化" class="headerlink" title="3. 优化"></a>3. 优化</h2><h3 id="存储优化"><a href="#存储优化" class="headerlink" title="存储优化"></a>存储优化</h3><p>​    由于网络带宽资源的昂贵性，因此对<code>MapReduce</code>  存储做了很多必要的优化。</p><ul><li>通过从本地磁盘读取文件，节约网络带宽</li><li>GFS 将文件分解成多个 大小通常为 64M 的<code>block</code>, 并多备份存储在不同的机器上，在调度时，会考虑文件的位置信息，尽可能在存有输入文件的机器上调度<code>map</code>任务，避免网络IO。</li><li>任务失败时，也会尝试在离副本最近的worker中执行，比如同一子网下的机器。</li><li>MapReduce 任务在大集群中执行时，大部分输入直接可以从磁盘中读取，不消耗带宽。</li></ul><h3 id="任务粒度"><a href="#任务粒度" class="headerlink" title="任务粒度"></a>任务粒度</h3><p>通常情况下，任务数即为 <code>O(M + R)</code>,  这个数量应当比<code>worker</code>数量多得多，这样利于负载均衡和失败恢复的情况，但是也不能无限增长，因为太多任务的调度，会消耗<code>master</code> 存储任务信息的内存资源，如果启动task所花的时间比任务执行时间还多，那就不偿失了。</p><h4 id="自定义分区函数-partition-："><a href="#自定义分区函数-partition-：" class="headerlink" title="自定义分区函数 (partition)："></a>自定义分区函数 (<code>partition</code>)：</h4><p>自定义分区可以更好地符合业务和进行负载均衡，防止数据倾斜。 默认只是简单的 <code>hash(key) % R</code></p><h4 id="有序保证："><a href="#有序保证：" class="headerlink" title="有序保证："></a>有序保证：</h4><p>每个<code>partition</code>内的数据都是排序的，这样有利于<code>Reduce</code>阶段的<code>merge</code>合并</p><h4 id="Combiner-函数："><a href="#Combiner-函数：" class="headerlink" title="Combiner 函数："></a><code>Combiner</code> 函数：</h4><p>这个是每个<code>map</code>阶段完成之后，局部先做一次聚合。比如：词频统计，每个 Word 可能出现了100次，如果不使用<code>combiner</code>， 就会发送100 个 <code>&lt;word, 1&gt;</code>, 如果<code>combiner</code>聚合之后，则为 <code>&lt;word, 100&gt;</code>, 大大地减少了网络传输和磁盘的IO。</p><h4 id="输入输出类型"><a href="#输入输出类型" class="headerlink" title="输入输出类型"></a>输入输出类型</h4><p>一个<code>reader</code>没必要非要从文件读数据，<code>MapReduce</code> 支持可以从不同的数据源中以多种不同的方式读取数据，比如从数据库读取，用户只需要自定义split规则，就能轻易实现。</p><h4 id="计数器"><a href="#计数器" class="headerlink" title="计数器"></a>计数器</h4><p><code>MapReduce</code> 还添加了计数器，可以用来检测<code>MapReduce</code>的一些中间操作。</p><h2 id="4-实现"><a href="#4-实现" class="headerlink" title="4. 实现"></a>4. 实现</h2><h3 id="初始代码逻辑"><a href="#初始代码逻辑" class="headerlink" title="初始代码逻辑"></a>初始代码逻辑</h3><h4 id="1-MapReduce应用"><a href="#1-MapReduce应用" class="headerlink" title="1. MapReduce应用"></a>1. MapReduce应用</h4><p><code>mrapps</code>文件夹里包含了很多<code>mapreduce</code>应用，比如wc.go(wordcount)，用来数单词频率的，每个应用都定义了自己的map函数和reduce函数，这里看一下wc.go里这两个函数的定义：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Map</span><span class="hljs-params">(filename <span class="hljs-keyword">string</span>, contents <span class="hljs-keyword">string</span>)</span> []<span class="hljs-title">mr</span>.<span class="hljs-title">KeyValue</span></span> &#123;<span class="hljs-comment">// function to detect word separators.</span>ff := <span class="hljs-function"><span class="hljs-keyword">func</span><span class="hljs-params">(r <span class="hljs-keyword">rune</span>)</span> <span class="hljs-title">bool</span></span> &#123; <span class="hljs-keyword">return</span> !unicode.IsLetter(r) &#125;<span class="hljs-comment">// split contents into an array of words.</span>words := strings.FieldsFunc(contents, ff)kva := []mr.KeyValue&#123;&#125;<span class="hljs-keyword">for</span> _, w := <span class="hljs-keyword">range</span> words &#123;kv := mr.KeyValue&#123;w, <span class="hljs-string">&quot;1&quot;</span>&#125;kva = <span class="hljs-built_in">append</span>(kva, kv)&#125;<span class="hljs-keyword">return</span> kva&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">Reduce</span><span class="hljs-params">(key <span class="hljs-keyword">string</span>, values []<span class="hljs-keyword">string</span>)</span> <span class="hljs-title">string</span></span> &#123;<span class="hljs-comment">// return the number of occurrences of this word.</span><span class="hljs-keyword">return</span> strconv.Itoa(<span class="hljs-built_in">len</span>(values))&#125;</code></pre><p>可以看到，定义很简单，map函数输出&lt;word, ‘1’&gt;，reduce函数输入聚合后众多个&lt;word,’1’&gt;，输出’1’的长度，即该单词出现的总次数。</p><p>将这个应用定义的函数和函数导出：</p><blockquote><p>go build -buildmode=plugin ../mrapps/wc.go</p></blockquote><p><strong>解释：</strong>plugin（插件）模式会把该文件的函数和变量导出到<code>.so</code>文件，其他文件可以通过引用<code>plugin</code>库来调用，可以看这里：<a href="https://medium.com/learning-the-go-programming-language/writing-modular-go-programs-with-plugins-ec46381ee1a9">https://medium.com/learning-the-go-programming-language/writing-modular-go-programs-with-plugins-ec46381ee1a9</a></p><h4 id="2-MapReduce过程"><a href="#2-MapReduce过程" class="headerlink" title="2. MapReduce过程"></a>2. MapReduce过程</h4><p>随后，启动sequential（串行，非并行）的示例：</p><blockquote><p>go run mrsequential.go wc.so pg*.txt</p></blockquote><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(os.Args) &lt; <span class="hljs-number">3</span> &#123;fmt.Fprintf(os.Stderr, <span class="hljs-string">&quot;Usage: mrsequential xxx.so inputfiles...\n&quot;</span>)os.Exit(<span class="hljs-number">1</span>)&#125;  <span class="hljs-comment">// 示例中，os.Args[1] = wc.so, 读取wc.so中定义的map函数和reduce函数，赋值给mapf和recudef变量</span>mapf, reducef := loadPlugin(os.Args[<span class="hljs-number">1</span>])<span class="hljs-comment">// Map过程，输出多个文件的map结果</span><span class="hljs-comment">// read each input file,</span><span class="hljs-comment">// pass it to Map,</span><span class="hljs-comment">// accumulate the intermediate Map output.</span><span class="hljs-comment">// </span>intermediate := []mr.KeyValue&#123;&#125;<span class="hljs-keyword">for</span> _, filename := <span class="hljs-keyword">range</span> os.Args[<span class="hljs-number">2</span>:] &#123;file, err := os.Open(filename)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;log.Fatalf(<span class="hljs-string">&quot;cannot open %v&quot;</span>, filename)&#125;content, err := ioutil.ReadAll(file)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;log.Fatalf(<span class="hljs-string">&quot;cannot read %v&quot;</span>, filename)&#125;file.Close()kva := mapf(filename, <span class="hljs-keyword">string</span>(content))intermediate = <span class="hljs-built_in">append</span>(intermediate, kva...)&#125;<span class="hljs-comment">//</span><span class="hljs-comment">// a big difference from real MapReduce is that all the</span><span class="hljs-comment">// intermediate data is in one place, intermediate[],</span><span class="hljs-comment">// rather than being partitioned into NxM buckets.</span><span class="hljs-comment">//</span>    <span class="hljs-comment">// 将中间结果排序</span>sort.Sort(ByKey(intermediate))oname := <span class="hljs-string">&quot;mr-out-0&quot;</span>ofile, _ := os.Create(oname)<span class="hljs-comment">// </span><span class="hljs-comment">// call Reduce on each distinct key in intermediate[],</span><span class="hljs-comment">// and print the result to mr-out-0.</span><span class="hljs-comment">//</span>i := <span class="hljs-number">0</span><span class="hljs-keyword">for</span> i &lt; <span class="hljs-built_in">len</span>(intermediate) &#123;j := i + <span class="hljs-number">1</span>    <span class="hljs-comment">//将相同的key找出来（这也是排序的意义）</span><span class="hljs-keyword">for</span> j &lt; <span class="hljs-built_in">len</span>(intermediate) &amp;&amp; intermediate[j].Key == intermediate[i].Key &#123;j++&#125;    <span class="hljs-comment">//将拥有相同的key的键值对合并</span>values := []<span class="hljs-keyword">string</span>&#123;&#125;<span class="hljs-keyword">for</span> k := i; k &lt; j; k++ &#123;values = <span class="hljs-built_in">append</span>(values, intermediate[k].Value)&#125;    <span class="hljs-comment">//输入到reduce函数里，得到输出</span>output := reducef(intermediate[i].Key, values)<span class="hljs-comment">// this is the correct format for each line of Reduce output.</span>fmt.Fprintf(ofile, <span class="hljs-string">&quot;%v %v\n&quot;</span>, intermediate[i].Key, output)i = j&#125;ofile.Close()&#125;</code></pre><p>这个示例演示了一个基础的MapReduce流程是怎样的。</p><h3 id="自己写代码"><a href="#自己写代码" class="headerlink" title="自己写代码"></a>自己写代码</h3><p>下来我们开始写代码吧！根据官方指引：</p><blockquote><p>One way to get started is to modify <code>mr/worker.go</code>‘s <code>Worker()</code> to send an RPC to the master asking for a task. Then modify the master to respond with the file name of an as-yet-unstarted map task. Then modify the worker to read that file and call the application Map function, as in <code>mrsequential.go</code>.</p></blockquote><p>我们来分析一下逻辑，在已经给出的串行MapReduce中，单一进程按照顺序执行Map任务和Reduce任务，但是在要实现的并行MapReduce中，我们将启动一个Master和多个Worker。</p><p>RPC教程可以看这里：<a href="https://golang.org/pkg/net/rpc/%EF%BC%8C%E7%AE%80%E5%8D%95%E6%9D%A5%E8%AF%B4%E5%B0%B1%E6%98%AF%E9%80%9A%E8%BF%87%E6%B3%A8%E5%86%8C%E5%AF%B9%E8%B1%A1%E6%9D%A5%E8%B0%83%E7%94%A8%E8%BF%9C%E7%A8%8B%E6%9C%8D%E5%8A%A1%E7%AB%AF%E7%9A%84%E5%87%BD%E6%95%B0%E3%80%82">https://golang.org/pkg/net/rpc/，简单来说就是通过注册对象来调用远程服务端的函数。</a></p><h4 id="1-数据结构分析"><a href="#1-数据结构分析" class="headerlink" title="1.数据结构分析"></a>1.数据结构分析</h4><pre><code class="hljs go"><span class="hljs-keyword">type</span> TaskStat <span class="hljs-keyword">struct</span> &#123;Status    TaskStatus <span class="hljs-comment">//task状态</span>WorkerId  <span class="hljs-keyword">int</span>        <span class="hljs-comment">//处理该task的worker序号</span>mu        sync.Mutex <span class="hljs-comment">//分段锁</span>StartTime time.Time  <span class="hljs-comment">//起始时间（用来计算有没有超时）</span>&#125;<span class="hljs-keyword">type</span> Master <span class="hljs-keyword">struct</span> &#123;files     []<span class="hljs-keyword">string</span>   <span class="hljs-comment">//需要处理的files</span>nReduce   <span class="hljs-keyword">int</span>        <span class="hljs-comment">//输入的参数nReduce（输入的文件会被划分成几个task来处理）</span>taskPhase TaskPhase  <span class="hljs-comment">//taskPhase（map阶段还是reduce阶段）</span>taskStats []TaskStat <span class="hljs-comment">//taskStats（各个task的状态）</span>mu        sync.Mutex <span class="hljs-comment">//mu（全局锁）</span>done      <span class="hljs-keyword">bool</span>       <span class="hljs-comment">//done（任务是否已完成）</span>workerSeq <span class="hljs-keyword">int</span>        <span class="hljs-comment">//workerSeq（有几个worker）</span>taskCh    <span class="hljs-keyword">chan</span> Task  <span class="hljs-comment">//taskCh（用来分发task的channel）</span>statCh    <span class="hljs-keyword">chan</span> <span class="hljs-keyword">bool</span>  <span class="hljs-comment">//statCh（用来接受各task状态的channel）</span>&#125;<span class="hljs-keyword">type</span> Task <span class="hljs-keyword">struct</span> &#123;FileName <span class="hljs-keyword">string</span>NReduce  <span class="hljs-keyword">int</span>NMaps    <span class="hljs-keyword">int</span>Seq      <span class="hljs-keyword">int</span>Phase    TaskPhaseAlive    <span class="hljs-keyword">bool</span> <span class="hljs-comment">// worker should exit when alive is false</span>&#125;</code></pre><h4 id="2-调用逻辑"><a href="#2-调用逻辑" class="headerlink" title="2.调用逻辑"></a>2.调用逻辑</h4><p>起始Master初始化后，后续启动的woker进程则会通过调用<code>RegWorker</code>在Master进程注册：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">RegWorker</span><span class="hljs-params">(args *RegisterArgs, reply *RegisterReply)</span> <span class="hljs-title">error</span></span> &#123;m.mu.Lock()<span class="hljs-keyword">defer</span> m.mu.Unlock()m.workerSeq++reply.WorkerId = m.workerSeq<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;</code></pre><p>随后woker进程会调用<code>GetOneTask</code>请求Master分配任务，Master会从taskChannel里获取一个task并初始化Task：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">GetOneTask</span><span class="hljs-params">(args *TaskArgs, reply *TaskReply)</span> <span class="hljs-title">error</span></span> &#123;task := &lt;-m.taskChreply.Task = &amp;task<span class="hljs-keyword">if</span> task.Alive &#123;m.regTask(args, &amp;task)&#125;DPrintf(<span class="hljs-string">&quot;in get one Task, args:%+v, reply:%+v&quot;</span>, args, reply)<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">regTask</span><span class="hljs-params">(args *TaskArgs, task *Task)</span></span> &#123;m.taskStats[task.Seq].mu.Lock()<span class="hljs-keyword">defer</span> m.taskStats[task.Seq].mu.Unlock()<span class="hljs-keyword">if</span> task.Phase != m.taskPhase &#123;<span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;req Task phase neq&quot;</span>)&#125;m.taskStats[task.Seq].Status = TaskStatusRunningm.taskStats[task.Seq].WorkerId = args.WorkerIdm.taskStats[task.Seq].StartTime = time.Now()&#125;</code></pre><p>获取Task之后，Woker进程根据Task的Phase不同分别进行不同的处理：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *worker)</span> <span class="hljs-title">doMapTask</span><span class="hljs-params">(t Task)</span></span> &#123;contents, err := ioutil.ReadFile(t.FileName)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;w.reportTask(t, <span class="hljs-literal">false</span>, err)<span class="hljs-keyword">return</span>&#125;kvs := w.mapf(t.FileName, <span class="hljs-keyword">string</span>(contents))reduces := <span class="hljs-built_in">make</span>([][]KeyValue, t.NReduce)<span class="hljs-keyword">for</span> _, kv := <span class="hljs-keyword">range</span> kvs &#123;idx := ihash(kv.Key) % t.NReducereduces[idx] = <span class="hljs-built_in">append</span>(reduces[idx], kv)&#125;<span class="hljs-keyword">for</span> idx, l := <span class="hljs-keyword">range</span> reduces &#123;fileName := reduceName(t.Seq, idx)f, err := os.Create(fileName)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;w.reportTask(t, <span class="hljs-literal">false</span>, err)<span class="hljs-keyword">return</span>&#125;enc := json.NewEncoder(f)<span class="hljs-keyword">for</span> _, kv := <span class="hljs-keyword">range</span> l &#123;<span class="hljs-keyword">if</span> err := enc.Encode(&amp;kv); err != <span class="hljs-literal">nil</span> &#123;w.reportTask(t, <span class="hljs-literal">false</span>, err)&#125;&#125;<span class="hljs-keyword">if</span> err := f.Close(); err != <span class="hljs-literal">nil</span> &#123;w.reportTask(t, <span class="hljs-literal">false</span>, err)&#125;&#125;w.reportTask(t, <span class="hljs-literal">true</span>, <span class="hljs-literal">nil</span>)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *worker)</span> <span class="hljs-title">doReduceTask</span><span class="hljs-params">(t Task)</span></span> &#123;maps := <span class="hljs-built_in">make</span>(<span class="hljs-keyword">map</span>[<span class="hljs-keyword">string</span>][]<span class="hljs-keyword">string</span>)<span class="hljs-keyword">for</span> idx := <span class="hljs-number">0</span>; idx &lt; t.NMaps; idx++ &#123;fileName := reduceName(idx, t.Seq)file, err := os.Open(fileName)<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;w.reportTask(t, <span class="hljs-literal">false</span>, err)<span class="hljs-keyword">return</span>&#125;dec := json.NewDecoder(file)<span class="hljs-keyword">for</span> &#123;<span class="hljs-keyword">var</span> kv KeyValue<span class="hljs-keyword">if</span> err := dec.Decode(&amp;kv); err != <span class="hljs-literal">nil</span> &#123;<span class="hljs-keyword">break</span>&#125;<span class="hljs-keyword">if</span> _, ok := maps[kv.Key]; !ok &#123;maps[kv.Key] = <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">string</span>, <span class="hljs-number">0</span>, <span class="hljs-number">100</span>)&#125;maps[kv.Key] = <span class="hljs-built_in">append</span>(maps[kv.Key], kv.Value)&#125;&#125;res := <span class="hljs-built_in">make</span>([]<span class="hljs-keyword">string</span>, <span class="hljs-number">0</span>, <span class="hljs-number">100</span>)<span class="hljs-keyword">for</span> k, v := <span class="hljs-keyword">range</span> maps &#123;res = <span class="hljs-built_in">append</span>(res, fmt.Sprintf(<span class="hljs-string">&quot;%v %v\n&quot;</span>, k, w.reducef(k, v)))&#125;<span class="hljs-keyword">if</span> err := ioutil.WriteFile(mergeName(t.Seq), []<span class="hljs-keyword">byte</span>(strings.Join(res, <span class="hljs-string">&quot;&quot;</span>)), <span class="hljs-number">0600</span>); err != <span class="hljs-literal">nil</span> &#123;w.reportTask(t, <span class="hljs-literal">false</span>, err)&#125;w.reportTask(t, <span class="hljs-literal">true</span>, <span class="hljs-literal">nil</span>)&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(w *worker)</span> <span class="hljs-title">reportTask</span><span class="hljs-params">(t Task, done <span class="hljs-keyword">bool</span>, err error)</span></span> &#123;<span class="hljs-keyword">if</span> err != <span class="hljs-literal">nil</span> &#123;log.Printf(<span class="hljs-string">&quot;%v&quot;</span>, err)&#125;args := ReportTaskArgs&#123;&#125;args.Done = doneargs.Seq = t.Seqargs.Phase = t.Phaseargs.WorkerId = w.idreply := ReportTaskReply&#123;&#125;<span class="hljs-keyword">if</span> ok := call(<span class="hljs-string">&quot;Master.ReportTask&quot;</span>, &amp;args, &amp;reply); !ok &#123;DPrintf(<span class="hljs-string">&quot;report task fail:%+v&quot;</span>, args)&#125;&#125;</code></pre><p>完成任务后，Worker进程向Master进程汇报，并重新循环请求新任务，Master进程判断当前任务的合法性以及是否正常完成，如果正常结束则启动一次单次全局调度来刷新状态：</p><pre><code class="hljs go"><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">ReportTask</span><span class="hljs-params">(args *ReportTaskArgs, reply *ReportTaskReply)</span> <span class="hljs-title">error</span></span> &#123;m.taskStats[args.Seq].mu.Lock()<span class="hljs-keyword">defer</span> m.taskStats[args.Seq].mu.Unlock()DPrintf(<span class="hljs-string">&quot;get report task: %+v, taskPhase: %+v&quot;</span>, args, m.taskPhase)<span class="hljs-keyword">if</span> m.taskPhase != args.Phase || args.WorkerId != m.taskStats[args.Seq].WorkerId &#123;<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;<span class="hljs-keyword">if</span> args.Done &#123;m.taskStats[args.Seq].Status = TaskStatusFinish&#125; <span class="hljs-keyword">else</span> &#123;m.taskStats[args.Seq].Status = TaskStatusErr&#125;<span class="hljs-keyword">go</span> m.tickSingleTimer()<span class="hljs-keyword">return</span> <span class="hljs-literal">nil</span>&#125;</code></pre><h4 id="3-Master调度过程"><a href="#3-Master调度过程" class="headerlink" title="3.Master调度过程"></a>3.Master调度过程</h4><p>在Worker进程在处理任务时，Master进程也在进行调度：</p><pre><code class="hljs go"><span class="hljs-comment">//只要任务没有完成结束就定期启用调度</span><span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">tickSchedule</span><span class="hljs-params">()</span></span> &#123;<span class="hljs-keyword">for</span> !m.Done() &#123;m.tickSingleTimer()time.Sleep(ScheduleInterval)&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">tickSingleTimer</span><span class="hljs-params">()</span></span> &#123;allFinish := <span class="hljs-literal">true</span><span class="hljs-keyword">var</span> wg sync.WaitGroupwg.Add(<span class="hljs-built_in">len</span>(m.taskStats))<span class="hljs-keyword">for</span> index := <span class="hljs-keyword">range</span> m.taskStats &#123;<span class="hljs-keyword">go</span> m.taskSchedule(index, &amp;wg) <span class="hljs-comment">//对每个taskstate都启用单独的goroutine调度</span>&#125;<span class="hljs-keyword">for</span> <span class="hljs-keyword">range</span> m.taskStats &#123;finStat := &lt;-m.statCh<span class="hljs-comment">//从信道中读取状态</span>allFinish = allFinish &amp;&amp; finStat&#125;wg.Wait()<span class="hljs-comment">//等待goroutines都结束（不然后面更新phase的时候全局锁不覆盖局部锁就会产生竞争）</span><span class="hljs-keyword">if</span> allFinish &#123;<span class="hljs-keyword">if</span> m.taskPhase == MapPhase &#123;log.Println(<span class="hljs-string">&quot;map done&quot;</span>)m.initReduceTask()&#125; <span class="hljs-keyword">else</span> &#123;m.mu.Lock()m.done = <span class="hljs-literal">true</span>m.mu.Unlock()&#125;&#125;&#125;<span class="hljs-function"><span class="hljs-keyword">func</span> <span class="hljs-params">(m *Master)</span> <span class="hljs-title">taskSchedule</span><span class="hljs-params">(taskSeq <span class="hljs-keyword">int</span>, wg *sync.WaitGroup)</span></span> &#123;<span class="hljs-keyword">if</span> m.Done() &#123;<span class="hljs-keyword">return</span>&#125;m.taskStats[taskSeq].mu.Lock()DPrintf(<span class="hljs-string">&quot;begin,task:%v, Status: %v&quot;</span>, taskSeq, m.taskStats[taskSeq].Status)<span class="hljs-keyword">switch</span> m.taskStats[taskSeq].Status &#123;<span class="hljs-keyword">case</span> TaskStatusReady:<span class="hljs-comment">//初始状态，将其放入task channel</span>m.statCh &lt;- <span class="hljs-literal">false</span>m.taskCh &lt;- m.getTask(taskSeq)m.taskStats[taskSeq].Status = TaskStatusQueue<span class="hljs-keyword">case</span> TaskStatusQueue:<span class="hljs-comment">//排队中，未被worker领取</span>m.statCh &lt;- <span class="hljs-literal">false</span><span class="hljs-keyword">case</span> TaskStatusRunning:<span class="hljs-comment">//正在被worker处理，判断一下时间有没有超时</span>m.statCh &lt;- <span class="hljs-literal">false</span><span class="hljs-keyword">if</span> time.Now().Sub(m.taskStats[taskSeq].StartTime) &gt; MaxTaskRunTime &#123;m.taskStats[taskSeq].Status = TaskStatusQueuem.taskCh &lt;- m.getTask(taskSeq)&#125;<span class="hljs-keyword">case</span> TaskStatusFinish:<span class="hljs-comment">//正常结束的task</span>m.statCh &lt;- <span class="hljs-literal">true</span><span class="hljs-keyword">case</span> TaskStatusErr:<span class="hljs-comment">//错误结束的task，将其重新放入队列中</span>m.statCh &lt;- <span class="hljs-literal">false</span>m.taskStats[taskSeq].Status = TaskStatusQueuem.taskCh &lt;- m.getTask(taskSeq)<span class="hljs-keyword">default</span>:<span class="hljs-comment">//异常状态</span>m.statCh &lt;- <span class="hljs-literal">false</span><span class="hljs-built_in">panic</span>(<span class="hljs-string">&quot;t.status err&quot;</span>)&#125;<span class="hljs-keyword">defer</span> m.taskStats[taskSeq].mu.Unlock()<span class="hljs-keyword">defer</span> wg.Done()&#125;</code></pre><p>以上就是MapReduce我个人的一些心得了。</p><p>代码参考：</p><ol><li><a href="https://titanssword.github.io/2018-01-20-mapreduce%20implements.html">https://titanssword.github.io/2018-01-20-mapreduce%20implements.html</a></li><li><a href="https://github.com/kophy/6.824">https://github.com/kophy/6.824</a></li></ol>]]></content>
    
    
    <categories>
      
      <category>分布式系统</category>
      
      <category>6.824</category>
      
    </categories>
    
    
    <tags>
      
      <tag>分布式系统</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
